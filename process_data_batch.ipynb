{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# III - `Process Data`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config IPython.matplotlib.backend = \"retina\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rcParams\n",
    "rcParams['figure.figsize'] = 10, 7\n",
    "rcParams[\"figure.dpi\"] = 150\n",
    "rcParams[\"savefig.dpi\"] = 150\n",
    "\n",
    "import transit\n",
    "import emcee\n",
    "import corner\n",
    "\n",
    "import astroML \n",
    "from astroML.plotting import setup_text_plots\n",
    "#setup_text_plots(fontsize=14, usetex=True)\n",
    "\n",
    "import astropy\n",
    "from astropy import constants as const\n",
    "from astropy import units as u\n",
    "from astropy.modeling import models, fitting\n",
    "from astropy.io import fits\n",
    "from astropy.table import Table\n",
    "\n",
    "from scipy import stats\n",
    "import scipy.optimize as op\n",
    "import scipy.signal as sig\n",
    "from scipy.signal import argrelextrema, medfilt\n",
    "from random import uniform, randrange\n",
    "\n",
    "import kplr\n",
    "from kplr.ld import get_quad_coeffs\n",
    "\n",
    "import time\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_file = '/Users/mbadenas/Documents/Master UAB/Tesis UAB/TFM2018/clean_bat_files/LC_p13point5up/'\n",
    "path_mergedLC = '/Users/mbadenas/Documents/Master UAB/Tesis UAB/TFM2018/merge_light_curves/LC_p13point5up_merged/'\n",
    "\n",
    "properties_sample = pd.read_csv(path_file+'all_targets_P13point5up.csv', sep=',', comment='#')\n",
    "targets = pd.read_csv(path_file + 'kepler_id.txt',delimiter=',', dtype=int, header=None, names=['kepid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(targets, properties_sample, on=['kepid'], how='inner') \n",
    "sc_data = df.drop_duplicates('kepid') #remove duplicates (some systems have both sc and lc LC)\n",
    "\n",
    "print(\"Check files:\")\n",
    "\n",
    "if (len(targets) != len(properties_sample)):\n",
    "    print(\"*Lengths don't match:\", len(targets), len(properties_sample))\n",
    "    print(\"\\tSome systems have both sc and lc data! Remove duplicates.\")\n",
    "\n",
    "if (len(sc_data) == len(targets)):\n",
    "    print(\"*Lengths match:\", len(sc_data), len(targets))\n",
    "    print('\\tDuplicates have been removed.\\n A total of {} systems have *short-cadence* LC with SN > 7.1 for their first transit and only 1 planet'.format(len(sc_data)))\n",
    "    \n",
    "sc_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the Systems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class System:    \n",
    "    def __init__(self, kepid, rs, rs_err, smass, smass_err, teff, logg, feh, srho,\n",
    "                time_BKJD, flux, flux_err, \n",
    "                t0, P, depth, b, duration, u1, u2, diffld, num_planets, incl, eccen, dor, sma,\n",
    "                 transit_times,ind_missed_transits,\n",
    "                rp, rp_err, teq, mp, \n",
    "                 trans_id, ftrans, ftrans_err, ttrans,dt_trans,\n",
    "                res_transfit, P_distribution, MCMC_transits):\n",
    "        \n",
    "        \"\"\"****** Kepler Reported Stellar Parameters ******\"\"\"\n",
    "        self.kepid = kepid\n",
    "        self.rs = rs # [Solar radii]. \n",
    "        self.rs_err = rs_err\n",
    "        self.smass = smass # [Solar mass]\n",
    "        self.smass_err = smass_err\n",
    "        \n",
    "        self.teff = teff;     \n",
    "        self.logg = logg; # Stellar Surface Gravity [log10(cm/s**2)]  \n",
    "        self.feh = feh;   \n",
    "        self.srho = srho; #g/cm3\n",
    "        \n",
    "        \"\"\"****** LC parameters ******\"\"\"\n",
    "        self.time_BKJD = time_BKJD\n",
    "        self.flux = flux\n",
    "        self.flux_err = flux_err\n",
    "        \n",
    "        \"\"\"****** Transit Parameters ******\"\"\"\n",
    "        self.t0 = t0\n",
    "        self.P = P;            \n",
    "        self.depth = depth;  \n",
    "        self.b = b; \n",
    "        self.duration = duration; \n",
    "        self.u1 = u1; \n",
    "        self.u2 = u2\n",
    "        self.diffld = 0.0\n",
    "        self.num_planets = num_planets\n",
    "        self.incl = incl #[º]\n",
    "        self.eccen = 0.0\n",
    "        self.dor = dor #Planet-Star Distance over Star Radius\n",
    "        self.sma = sma #Orbital semi-major axis [AU]\n",
    "        \n",
    "        self.transit_times = transit_times\n",
    "        self.ind_missed_transits = ind_missed_transits\n",
    "        #self.depth = rprs ** 2 \n",
    "            # Transit depth in absolute terms. To 1st order (assuming stellar disk has uniform brightness and \n",
    "            # neglecting any flux coming from planet), the ratio X of the observed change in flux, Delta(F), \n",
    "            # to that of the stellar flux F is: X = (Rp/Rs)^2 = depth.\n",
    "                   \n",
    "        \"\"\"****** Planetary Parameters ******\"\"\"\n",
    "        self.rp = rp # [Earth radii]. This is \"prad\"  in the original file\n",
    "        self.rp_err = rp_err\n",
    "        self.teq = teq\n",
    "        self.mp = 2.69*(rp)**(0.93) #Weiss & Marcy rel'n. It requires Rp in Earth radii\n",
    "        \n",
    "        \"\"\"****** Internal Variables ******\"\"\"\n",
    "        self.trans_id = np.empty(0)\n",
    "        self.ftrans = np.empty(0)\n",
    "        self.ftrans_err = np.empty(0)\n",
    "        self.ttrans = np.empty(0)\n",
    "        self.dt_trans = np.empty(0)\n",
    "        self.res_transfit = np.empty(0)\n",
    "        self.P_distribution = np.empty(0)\n",
    "        self.MCMC_transits = np.empty(0)\n",
    "        \n",
    "    def Print(self):\n",
    "        print(\"System {}\".format(self.kepid))\n",
    "        print('rho={0:0.3f}, logg={1:0.3f} [log10(cm/s**2)], a={2:0.3f} [AU]'.format(self.srho, self.logg,self.sma))\n",
    "        print(\"Impact parameter b:\",self.b)\n",
    "        print(\"Depth {0:0.2f} (or {1:0.2f} in ppm)\".format(self.depth, self.depth*1e6))\n",
    "        print(\"u1: {0:0.3f}, u2: {1:0.3f}\".format(self.u1,self.u2))\n",
    "        print(\"Temperature [K]:\",self.teff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Characterize the Systems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some initialization functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bjd_ref = 2454833\n",
    "\n",
    "def quadraticLD(T, G, FEH): \n",
    "    \"\"\"Confirm the quadratic LD coefficients with a model from Claret & Bloemen (2011).\n",
    "    Use the Claret coefficients instead.\"\"\"\n",
    "    mu1, mu2 = get_quad_coeffs(T, G, FEH)\n",
    "    return (mu1, mu2)\n",
    "\n",
    "def fetchLC(name):\n",
    "    id_kep = \"%.0f\" % name\n",
    "    lc = path_mergedLC+('KID'+id_kep+'.txt')\n",
    "    df = pd.read_csv(lc, sep=\"\\t\", skiprows=1, header=None, names=[\"Time BKJD\", \"Flux\", \"Flux_Err\"])\n",
    "    y = df['Flux']\n",
    "    yerr = df['Flux_Err']\n",
    "    x = df['Time BKJD']\n",
    "    #print(np.median(y),np.mean(y),np.std(y))\n",
    "    return (y, yerr, x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the planet+star system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = []\n",
    "\n",
    "for row in sc_data.itertuples(index = True, name='Pandas'):\n",
    "    kepid = getattr(row, \"kepid\")\n",
    "    fluxLC, fluxLC_err, timeLC_BKJD = fetchLC(kepid)\n",
    "\n",
    "    ## Store the stellar parameters\n",
    "    rs = getattr(row, \"koi_srad\") #solar radii\n",
    "    smass = getattr(row, \"koi_smass\")\n",
    "    #Assuming that we have a 5% error on radius and mass (this is sensible thanks to Gaia)\n",
    "    rs_err = rs*0.05\n",
    "    smass_err = smass*0.05\n",
    "    \n",
    "    #rs_errPos = getattr(row, \"koi_srad_err1\"); rs_errNeg = getattr(row, \"koi_srad_err2\")\n",
    "    #rs_err = np.abs((rs_errPos+rs_errNeg)/2.)\n",
    "    \n",
    "    #smass_errPos = getattr(row, \"koi_smass_err1\"); smass_errNeg = getattr(row, \"koi_smass_err2\")\n",
    "    #smass_err = np.abs((smass_errPos+smass_errNeg)/2.)\n",
    "    \n",
    "    teff = getattr(row, \"koi_steff\")\n",
    "    logg = getattr(row, \"koi_slogg\") # Stellar Surface Gravity [log10(cm/s**2)]  \n",
    "    feh = getattr(row, \"koi_smet\")\n",
    "    srho = getattr(row, \"koi_srho\") #g/cm3\n",
    "    \n",
    "    #### Store LC Parameters\n",
    "    t0 = getattr(row, \"koi_time0bk\")\n",
    "    P = getattr(row, \"koi_period\") # Orbital Period [days]\n",
    "    depth = getattr(row, \"koi_depth\")/1e6\n",
    "    b = getattr(row, \"koi_impact\")\n",
    "    \n",
    "    u1, u2 = quadraticLD(teff,logg,feh)\n",
    "\n",
    "    num_planets = getattr(row, \"koi_count\")\n",
    "    incl =  getattr(row, \"koi_incl\") #in degrees\n",
    "    dor = getattr(row, \"koi_dor\")  #Planet-Star Distance over Star Radius\n",
    "    \n",
    "    time0bk = getattr(row, \"koi_time0bk\")\n",
    "    duration = getattr(row, \"koi_duration\")/24. #in days. \"Duration is measured from first contact between the planet and star until last contact.\"\n",
    "    \n",
    "    #Planetary parameters\n",
    "    sma = getattr(row, \"koi_sma\")  #Orbit Semi-Major Axis [AU]\n",
    "    sma_solarRad = sma*215\n",
    "    teq = getattr(row, \"koi_teq\") \n",
    "    rp = getattr(row, \"koi_prad\") # in Earth radii\n",
    "    rp_solarRad = getattr(row, \"koi_prad\")*0.009168 # in solar radii\n",
    "    rp_errPos = getattr(row, \"koi_prad_err1\"); rp_errNeg = getattr(row, \"koi_prad_err2\")\n",
    "    rp_err = np.abs((rp_errPos+rp_errNeg)/2.)\n",
    "        \n",
    "    if (num_planets == 1):\n",
    "        system = System(kepid, rs, rs_err, smass, smass_err, teff, logg, feh, srho,\n",
    "                    timeLC_BKJD, fluxLC, fluxLC_err, \n",
    "                    t0, P, depth, b, duration, u1, u2, u1-u2, num_planets, incl, 0.0, dor, sma,\n",
    "                        None, None,\n",
    "                    rp, rp_err, teq, None, \n",
    "                        None, None, None, None, None,\n",
    "                       None, None, None)\n",
    "\n",
    "        targets.append(system)\n",
    "                \n",
    "    else:\n",
    "        print('Star {:s} not stored (koi_count > 1)'.format(str(kepid)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transit Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_transits(star):\n",
    "    ti = min(star.time_BKJD)\n",
    "    tf = max(star.time_BKJD)\n",
    "    \n",
    "    n_min = int((ti-star.t0)/star.P)\n",
    "    n_max = int((tf-star.t0)/star.P+1.)\n",
    "    n = np.arange(n_min, n_max)\n",
    "    \n",
    "    t = star.t0+n*star.P\n",
    "    t = t[t>ti] \n",
    "    t = t[t<tf]\n",
    "    return(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_folded_lightcurve(star, plot=False):\n",
    "    if plot==True:\n",
    "        plt.figure(figsize=(15,6))\n",
    "        plt.plot(star.dt_trans,star.ftrans,'.')     \n",
    "        plt.title(r'Folded LC for KID'+str(star.kepid))\n",
    "        plt.xlabel(r'Time BKJD [d]'); plt.ylabel('Normalized Flux')\n",
    "        plt.show(block=False)    \n",
    "        time.sleep(0.3)\n",
    "        plt.close()\n",
    "\n",
    "def mark_transits(star, obs_trans, plot=False):\n",
    "    if plot==True:\n",
    "        plt.figure(figsize=(15,6))\n",
    "        plt.plot(star.time_BKJD,star.flux,'.')        \n",
    "        for j in range(len(star.transit_times)): \n",
    "            plt.axvline(star.transit_times[j], color='k', ls='-')\n",
    "        for k in range(len(obs_trans)): \n",
    "            plt.axvline(obs_trans[k], color='r', ls='--')\n",
    "        plt.title(r'KID'+str(star.kepid))\n",
    "        plt.xlabel(r'Time BKJD [d]'); plt.ylabel(r'Normalized Flux')\n",
    "        plt.show(block=False)    \n",
    "        time.sleep(0.3)\n",
    "        plt.close()\n",
    "        \n",
    "def show_transits(star, bad_trans, plot=False):        \n",
    "    s1 = set(bad_trans)\n",
    "    if plot==True:   \n",
    "        for i in range(len(star.transit_times)):\n",
    "            if (i not in bad_trans):\n",
    "                plt.figure(figsize=(15,6))\n",
    "                plt.title('Folded Light Curve')\n",
    "                plt.plot(star.ttrans[star.trans_id==i]-star.transit_times[i],star.ftrans[star.trans_id==i], 'k.')     \n",
    "                plt.title(\"Transit \"+str(i+1))\n",
    "                plt.xlabel(r'Time [d]'); plt.ylabel('Normalized Flux')\n",
    "                plt.show(block=False)    \n",
    "                time.sleep(0.3)\n",
    "                plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_in_transit(star, factor):\n",
    "    window = factor*star.duration # In days\n",
    "    total_points = 0\n",
    "    \n",
    "    for i in range(0,len(star.transit_times)):\n",
    "        residual = star.time_BKJD - star.transit_times[i]\n",
    "        points_in_transit = np.abs(residual) <= window\n",
    "        total_points += np.sum(points_in_transit)\n",
    "\n",
    "    time_in_transit = np.empty(total_points)\n",
    "    flux_in_transit = np.empty(total_points)\n",
    "    flux_err_in_transit = np.empty(total_points)\n",
    "    flag_transit = np.empty(total_points)\n",
    "    mid_trans = np.empty(total_points)\n",
    "\n",
    "    total_points = 0\n",
    "\n",
    "    for i in range(0, len(star.transit_times)):\n",
    "        points_in_transit = np.abs(star.time_BKJD - star.transit_times[i]) <= window\n",
    "        count_points = np.sum(points_in_transit)\n",
    "        time_in_transit[(0 + total_points):(count_points + total_points)] = star.time_BKJD[points_in_transit]\n",
    "        flux_in_transit[(0 + total_points):(count_points + total_points)] = star.flux[points_in_transit] #, star.flux_err[points_in_transit])[0]\n",
    "        flux_err_in_transit[(0 + total_points):(count_points + total_points)] = star.flux_err[points_in_transit] #normalize(star.flux[points_in_transit], \n",
    "        flag_transit[(0 + total_points):(count_points + total_points)] = i\n",
    "        mid_trans[(0 + total_points):(count_points + total_points)] = star.transit_times[i] \n",
    "        total_points += count_points\n",
    "        \n",
    "        \n",
    "    star.trans_id = flag_transit\n",
    "    star.ttrans = time_in_transit\n",
    "    star.ftrans = flux_in_transit\n",
    "    star.ftrans_err = flux_err_in_transit\n",
    "    star.dt_trans = time_in_transit - mid_trans #if interested in the folded LC, plot target.dt_trans vs target.ftrans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def oot_fit(star, polyorder, factor):\n",
    "    window = factor*star.duration \n",
    "    transit_range = window/2 # In days\n",
    "    for i in range(0, len(star.transit_times)):\n",
    "        transitBool = (star.trans_id == i)\n",
    "        outsideBool = (np.abs(star.dt_trans) >= transit_range) & transitBool\n",
    "        f_out = star.ftrans[outsideBool]\n",
    "        num_oot_points = len(star.dt_trans[outsideBool])\n",
    "        rms = np.sqrt(np.mean(f_out**2))\n",
    "        \n",
    "        if  (num_oot_points!= 0):  \n",
    "            z = np.polyfit(star.dt_trans[outsideBool], f_out, polyorder)\n",
    "            p = np.poly1d(z)\n",
    "            star.ftrans[transitBool] = star.ftrans[transitBool]/p(star.dt_trans[transitBool]) # Divide transit by fit.\n",
    "            \n",
    "            snr_trans = np.mean(star.ftrans[transitBool])/np.std(star.ftrans[transitBool])\n",
    "            print(\"Transit #{0:s}: \\t RMS={1:0.5f}\\tflux_min={2:0.4f}\".format(str(i+1),rms,min(star.ftrans[transitBool])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_missed_transits(star):\n",
    "    gaps = []\n",
    "    for i in range(len(star.transit_times)):\n",
    "        if len(star.ttrans[star.trans_id==i])==0: \n",
    "            gaps.append(i)\n",
    "    missing_transits = sorted(gaps, reverse=True)\n",
    "    return(missing_transits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below performs two functions: \n",
    "    1. It identifies the light curves that don't have a visible transit. (With the data being used as of June 30, this amounts to 4 systems).\n",
    "    2. For the remaining light curves, it calculates all the expected transits and then looks at which transits are actually visible (sometimes, there are gaps in the data and transits are lost). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stars_wo_transits = []\n",
    "medfilter = 13\n",
    "poly_order = 2\n",
    "amplify = 1.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for target in targets:\n",
    "    print(\"\\n**** KID\"+str(target.kepid)+\" ****\\n\")\n",
    "    \n",
    "    target.flux = sig.medfilt(target.flux, medfilter)\n",
    "    target.transit_times = find_transits(target)\n",
    "    get_data_in_transit(target, amplify)\n",
    "    oot_fit(target, poly_order, amplify)\n",
    "       \n",
    "    if (len(target.transit_times)==0): stars_wo_transits.append(target.kepid)\n",
    "    \n",
    "    target.ind_missed_transits = find_missed_transits(target)\n",
    "    observed_transits = np.delete(target.transit_times, target.ind_missed_transits)\n",
    "    mark_transits(target, observed_transits, False)\n",
    "    show_transits(target, target.ind_missed_transits, False)\n",
    "\n",
    "    if len(observed_transits!=0): \n",
    "        show_folded_lightcurve(target, False)\n",
    "    \n",
    "    print(\"Transit duration:\", target.duration)\n",
    "    print(\"Period: {0:s} [d]\".format(str(target.P)))\n",
    "    print(\"Estimated transits at ({0:s}):\".format(str(len(target.transit_times))), target.transit_times)\n",
    "    print(\"Observed transits at ({0:s}):\".format(str(len(observed_transits))), observed_transits)\n",
    "    print(\"Index of missed transits:\", target.ind_missed_transits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"There are {:s} stars without transits. These targets won't be studied\".format(str(len(stars_wo_transits))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fitting a Theoretical Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transit Routine (DFM)\n",
    "\n",
    "A Python library for generating light curves of transiting planets. See https://github.com/dfm/transit/blob/master/transit/transit.py for original code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ln_probtrans(P, rstar, mstar):\n",
    "    alog = (1/3)*np.log(mstar)+(2/3)*np.log(P)\n",
    "    prob = np.log(rstar)-alog\n",
    "    return(prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lnlike(theta, timeLC, fluxLC, errorLC, allfixed):\n",
    "    \"\"\"\n",
    "    Calculates the log of the likelihood of the transit model being the right model given the following parameters:\n",
    "    theta[0] = pdepth = (Rp/Rs)^2\n",
    "    theta[1] = pb = the mean impact parameter, measured in stellar radii (not Solar radii). See documentation.\n",
    "    theta[2] = sigma = an additional white noise term\n",
    "    theta[3] = pmass = the mass of the star (controlled via gaussian prior)\n",
    "    theta[4] = pradius = the radius of the star (controlled via gaussian prior)\n",
    "    theta[5] = f0 = the out of eclipse flux\n",
    "    theta[6] = pperiod = Orbital period \n",
    "    theta[7] = ptc = Transit time (time of conjunction) \n",
    "    \"\"\"\n",
    "    ecc, mass, masserr, radius, radiuserr, tKep, u1, u2 = allfixed\n",
    "    pdepth, pb, sigma, pmass, pradius, f0, pperiod, ptc = theta \n",
    "    \n",
    "    #Note: pmass and prad (stellar mass and radius) controlled via gaussian prior. By letting M* and R* be free parameters in the model, we allow the stellar density to fluctuate. \n",
    "    \n",
    "    s = transit.System(transit.Central(mu1=u1, mu2=u2, mass = pmass, radius = pradius))\n",
    "    body = transit.Body(radius=np.sqrt(pdepth)*pradius, period=pperiod, t0=ptc, b=np.abs(pb), e=ecc)\n",
    "    \n",
    "    s.add_body(body)\n",
    "    inv_sigma2 = 1.0/(errorLC**2 + sigma**2)\n",
    "    try: \n",
    "        ftheo = s.light_curve(timeLC, texp=tKep, tol=1e-08, maxdepth=4)\n",
    "    except ValueError:\n",
    "        return -np.inf\n",
    "    ftheo = ftheo-1+f0\n",
    "     \n",
    "    return -0.5*(np.sum((fluxLC-ftheo)**2*inv_sigma2 - np.log(inv_sigma2)) + ((pmass-mass)/masserr)**2\n",
    "            + ((pradius-radius)/radiuserr)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lnprior(theta):\n",
    "    ##https://github.com/stan-dev/stan/wiki/Prior-Choice-Recommendations\n",
    "    pdepth, pb, sigma, pmass, pradius, f0, pperiod, ptc = theta\n",
    "    if ((0 < pb < 1.2) and (0 <= sigma) and (pradius > 0) \n",
    "        and (pdepth > 0) and (pmass > 0.0) and (pperiod > 13.5)  and (ptc**2<0.01)):\n",
    "        return ln_probtrans(pperiod, pradius, pmass) \n",
    "    return -np.inf  \n",
    "\n",
    "def lnprior_MCMC(theta, maxDepth): ##https://github.com/stan-dev/stan/wiki/Prior-Choice-Recommendations\n",
    "    pdepth, pb, sigma, pmass, pradius, f0, pperiod, ptc = theta\n",
    "    if ((0 < pb < maxDepth) and (0 <= sigma) and (pradius > 0) \n",
    "        and (pdepth>0) and (pmass > 0.0) and (pperiod > 13.5)  and (ptc**2<0.01)):\n",
    "        return ln_probtrans(pperiod, pradius, pmass) \n",
    "    return -np.inf    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lnprob(theta, timeLC, fluxLC, errorLC, allfixed):\n",
    "    ecc, mass, masserr, radius, radiuserr, tKep, u1, u2 = allfixed\n",
    "    lp = lnprior(theta)\n",
    "    if not np.isfinite(lp):\n",
    "        return -np.inf\n",
    "    return lp + lnlike(theta, timeLC, fluxLC, errorLC, allfixed)\n",
    "\n",
    "def lnprob_MCMC(theta, timeLC, fluxLC, errorLC, allfixed_MCMC, maxDepth):\n",
    "    ecc, mass, masserr, radius, radiuserr, tKep, u1, u2 = allfixed_MCMC\n",
    "    lp_MCMC = lnprior_MCMC(theta, maxDepth)\n",
    "    if not np.isfinite(lp_MCMC):\n",
    "        return -np.inf\n",
    "    return lp_MCMC + lnlike(theta, timeLC, fluxLC, errorLC, allfixed_MCMC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_lc(nl, guesses, lc_data):\n",
    "    res = op.minimize(nl, guesses, lc_data, options={'maxiter': 1e4,'disp': False}, method='Nelder-Mead')\n",
    "    ml_fit = res[\"x\"] \n",
    "    return ml_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_transit_routine(star, t, f, ferr, transit_num):\n",
    "    period_guess = 250 #randrange(14,500) #uniform(13.5, 500) print(\"Period guess [d]:\", period_guess)\n",
    "    t_conj_guess = 0.0\n",
    "    depth_guess = 1-min(f)  #we take the minimum of the folded light curve\n",
    "    \n",
    "    allfixed = [star.eccen, star.smass, star.smass_err, star.rs, star.rs_err, tKep, star.u1, star.u2]\n",
    "    initial_guesses = [1.2*depth_guess, 0.5, 0.0, star.smass, star.rs, 1.0, period_guess, t_conj_guess] \n",
    "    \n",
    "    nll = lambda *args: -lnprob(*args)\n",
    "    \n",
    "    params0 = (t, f, 0.0, allfixed)\n",
    "    res0 = fit_lc(nll, initial_guesses, params0)\n",
    "    print(\"\\t\\t Period (fit 0): {:0.6f} days\".format(res0[6]))\n",
    "\n",
    "    params1 = (t, f, 0.01*ferr, allfixed)\n",
    "    res1 = fit_lc(nll, res0, params1)\n",
    "    print(\"\\t\\t Period (fit 1): {:0.6f} days\".format(res1[6]))\n",
    "\n",
    "    params2 = (t, f, ferr, allfixed)\n",
    "    res2 = fit_lc(nll, res1, params2)\n",
    "    \n",
    "    depth_ml, b_ml, sigma_ml, mass_ml, radius_ml, f0_ml, period_ml, tc_ml = res2\n",
    "    \n",
    "    # Compute the theoretical light curve integrated over a Kepler short-cadence exposure time.\n",
    "    s = transit.System(transit.Central(mu1=star.u1, mu2=star.u2, mass=mass_ml, radius=radius_ml))\n",
    "    body = transit.Body(radius=np.sqrt(depth_ml)*radius_ml,period=period_ml,t0=tc_ml,b=b_ml,e=star.eccen)\n",
    "    s.add_body(body)\n",
    "    t_fit = np.arange(-1, 1, tKep*0.01)\n",
    "    f_fit = s.light_curve(t_fit, texp=tKep, tol=1e-08, maxdepth=4)\n",
    "    f_fit = f_fit - 1.0 + f0_ml\n",
    "\n",
    "    fig = plt.figure(figsize=(16,5))\n",
    "    plt.title(\"KID\"+str(star.kepid)+\". Transit \"+str(transit_num+1), fontsize = 15)\n",
    "    plt.plot(t, f, '.', label = 'Kepler data')\n",
    "    plt.plot(t_fit, f_fit, color='r', lw = 3, label = 'Fit')\n",
    "    plt.xlabel('Time from midtransit [days]')\n",
    "    plt.ylabel('Relative flux')\n",
    "    plt.xlim([min(t),max(t)]) \n",
    "    plt.show(block=False)    \n",
    "    time.sleep(0.5)\n",
    "    plt.close()\n",
    "\n",
    "    #star.duration = body.duration #from eq'n 14 in Winn (2010)\n",
    "    print(\"------ Pre-MCMC Results ------\")\n",
    "    print(\"\\tTransit duration [d]:\\t Fit={0:0.3f}\\tTrue={1:0.3f}\".format(body.duration, star.duration))\n",
    "    print(\"\\tPeriod [days]:\\t Fit={0:0.8f}\\tTrue={1:0.8f}\".format(period_ml,star.P))\n",
    "    print(\"\\tImpact Parameter:\\t Fit={0:0.6f}\\tTrue={1:0.6f}\".format(b_ml,star.b))\n",
    "    print(\"\\tDepth:\\t Fit={0:0.6f}\\tTrue={1:0.6f}\".format(depth_ml,star.depth))\n",
    "    print(\"\\tStellar mass:\\t Fit={0:0.3f}\\tTrue={1:0.3f}\".format(mass_ml,star.smass))\n",
    "    print(\"\\tStellar radius:\\t Fit={0:0.3f}\\tTrue={1:0.3f}\".format(radius_ml,star.rs))\n",
    "    \n",
    "    return(res2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MCMC "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_mcmc(star, t, f, ferr, num_trans, fit_results, corner_plot, corner_store, \n",
    "             burnin_plot, burnin_store, show_mcmc_res, show_mcmc_lc):\n",
    "    \n",
    "    #----- IMPROVE PRIOR DEPTH UPPER BOUND  -----\n",
    "    depth_ml, b_ml, sigma_ml, mass_ml, radius_ml, f0_ml, period_ml, tc_ml = fit_results\n",
    "    rp_guess = np.sqrt(depth_ml)*star.rs\n",
    "    max_depth = 1+rp_guess/star.rs #(three_jup_rad/rs)**2\n",
    "    \n",
    "    print(\"\\n------ Prepare MCMC -------\")\n",
    "    print(\"Guess impact parameter:\", b_ml)\n",
    "    print(\"Guess of Rp [in Rsun]: \", rp_guess)\n",
    "    print(\"1+rp_guess/rs: \", max_depth)\n",
    "\n",
    "    #---------- INITIALIZE MCMC  ----------\n",
    "    #res_MCMC = [depth_ml, b_ml, sigma_ml, mass_ml, radius_ml, f0_ml, period_ml, tc_ml]\n",
    "    allfixed_MCMC = [star.eccen, star.smass, star.smass_err, star.rs, star.rs_err, tKep, star.u1, star.u2]\n",
    "    ndim = len(fit_results)\n",
    "    p0 = [fit_results*(1+1e-8*np.random.randn(ndim)) for i in range(nwalkers)]\n",
    "    \n",
    "    #---------- RUN MCMC ----------\n",
    "    sampler = emcee.EnsembleSampler(nwalkers, ndim, lnprob_MCMC, args=(t, f, ferr, allfixed_MCMC, max_depth))\n",
    "    \n",
    "    print(\"Running burn-in\")\n",
    "    pos, prob, state = sampler.run_mcmc(p0, 100, progress=True);\n",
    "    sampler.reset() # Reset the chain to remove the burn-in samples.\n",
    "    print(\"\\n------ Run MCMC -------\")\n",
    "    sampler.run_mcmc(p0, steps, rstate0 = state, progress=True);\n",
    "    samples = sampler.chain[:, int(steps/10):, :].reshape((-1, ndim)) #burnin currently set to 10%\n",
    "  \n",
    "    #Clipping extreme values (top.bottom 0.1 percentiles)\n",
    "    #toclip=np.array([(np.percentile(samples[:,t],99.9)>samples[:,t]) // (samples[:,t]>np.percentile(samples[:,t],0.1)) for t in range(ndim)]).all(axis=0)\n",
    "    #samples=samples[toclip]\n",
    "    \n",
    "    #---------- GET PERIOD DISTRIBUTION ----------\n",
    "    period_distribution = samples[:,6]\n",
    "    \n",
    "    #---------- PERCENTILES ---------- \n",
    "    #Get the 50% percentile and the +- 1 sigma error interval of the parameters and some derived quantities \n",
    "    #such as Rp and Rs/a. \n",
    "    \n",
    "    samples[:, 2] = np.exp(samples[:, 2])\n",
    "    planetradsamp = 109.045*np.sqrt(samples[:,0])*samples[:, 4] #in earth rad (rp = sqrt(depth)*rs)\n",
    "    P1 = period_ml*24.0*3600.0 #in sec\n",
    "    r_asamp = ((3.0*np.pi/(G*P1**2))*((samples[:,5]**3/samples[:, 4])/1408.0))**0.3333\n",
    "\n",
    "    depth_mcmc, b_mcmc, sigma_mcmc, smass_mcmc, rs_mcmc, \\\n",
    "    f0_mcmc, period_mcmc, tc_mcmc = map(lambda v: (v[1], v[2]-v[1], v[1]-v[0]), \n",
    "                               zip(*np.percentile(samples, [15.86, 50, 84.14], axis=0)))\n",
    "    \n",
    "    v = np.percentile(planetradsamp, [15.86, 50, 84.14], axis=0)\n",
    "    planetrad_mcmc =(v[1], v[2]-v[1], v[1]-v[0])\n",
    "\n",
    "    v = np.percentile(r_asamp, [15.86, 50, 84.14], axis=0)\n",
    "    r_a_mcmc =(v[1], v[2]-v[1], v[1]-v[0])\n",
    "    \n",
    "    results_mcmc = [depth_mcmc, b_mcmc, sigma_mcmc, smass_mcmc, rs_mcmc, f0_mcmc, \n",
    "                    period_mcmc, tc_mcmc, planetrad_mcmc, r_a_mcmc]\n",
    "    \n",
    "    if show_mcmc_res == True:\n",
    "        print(\"\\n------ Post-MCMC Results ------\")\n",
    "        print(\"\\nDepth:\\n\\tTrue = {:0.3f}\".format(star.depth))\n",
    "        print(\"\\tMCMC Fit = {0:0.3f} (+{1:0.3f},-{2:0.3f})\".format(depth_mcmc[0],depth_mcmc[1],depth_mcmc[2]))\n",
    "        print(\"\\nImpact parameter:\\n\\tTrue = {:0.3f}\".format(star.b))\n",
    "        print(\"\\tMCMC Fit = {0:0.3f} (+{1:0.3f},-{2:0.3f})\".format(b_mcmc[0],b_mcmc[1],b_mcmc[2]))\n",
    "        print(\"\\nPlanet radius [REarth]:\\n\\tTrue = {:0.3f}\".format(star.rp))\n",
    "        print(\"\\tMCMC Fit = {0:0.3f} (+{1:0.3f},-{2:0.3f})\".format(planetrad_mcmc[0],planetrad_mcmc[1],planetrad_mcmc[2]))\n",
    "        print(\"\\nPeriod [d]:\\n\\tTrue = {:0.3f}\".format(star.P))\n",
    "        print(\"\\tMCMC Fit = {0:0.3f} (+{1:0.3f},-{2:0.3f})\".format(period_mcmc[0],period_mcmc[1],period_mcmc[2]))\n",
    "        print(\"\\nInverse of scaled semi-major axis:\\n\\tTrue = {:0.4f}\".format(1/star.dor))\n",
    "        print(\"\\tMCMC Fit = {0:0.4f} (+{1:0.4f},-{2:0.4f})\".format(r_a_mcmc[0],r_a_mcmc[1],r_a_mcmc[2]))\n",
    "        print(\"\\nStellar radius [Rsun]:\\n\\tTrue = {:0.3f}\".format(star.rs))\n",
    "        print(\"\\tMCMC Fit = {0:0.3f} (+{1:0.3f},-{2:0.3f})\".format(rs_mcmc[0],rs_mcmc[1],rs_mcmc[2]))\n",
    "        print(\"\\nStellar Mass [Msun]:\\n\\tTrue = {:0.3f}\".format(star.smass))\n",
    "        print(\"\\tMCMC Fit = {0:0.3f} (+{1:0.3f},-{2:0.3f})\".format(smass_mcmc[0],smass_mcmc[1],smass_mcmc[2]))\n",
    "\n",
    "   \n",
    "    #---------- Plot the LC with the MCMC fit ----------\n",
    "    if show_mcmc_lc == True:\n",
    "        s = transit.System(transit.Central(mu1=star.u1, mu2=star.u2, mass=smass_mcmc[0], radius=rs_mcmc[0]))\n",
    "        body = transit.Body(radius=np.sqrt(depth_mcmc[0])*rs_mcmc[0], period=period_mcmc[0], \n",
    "                            t0=tc_mcmc[0], b=b_mcmc[0], e=star.eccen)\n",
    "        s.add_body(body)\n",
    "        t_fit = np.arange(-1, 1, tKep * 0.01)\n",
    "        f_fit = s.light_curve(t_fit, texp=tKep, tol=1e-08, maxdepth=4)\n",
    "        f_fit = f_fit - 1.0 + f0_mcmc[0]\n",
    "        #plt.clf()\n",
    "        fig_lc = plt.figure(figsize=(15,4))\n",
    "        plt.title('MCMC Fit for KID'+str(star.kepid))\n",
    "        plt.plot(t, f, '.', label = 'kepler')\n",
    "        plt.plot(t_fit, f_fit, 'r', lw = 3, label = 'fit')\n",
    "        plt.xlim([min(t),max(t)]) \n",
    "        \n",
    "        file_path_fit = '/Users/mbadenas/Documents/Master UAB/Tesis UAB/TFM2018/results/MCMC_fits/'\n",
    "        store_mcmc_fit = \"fit\"+str(star.kepid)+\"_st\"+str(steps)+\"_trans\"+str(num_trans+1)+\".png\"\n",
    "        fig_lc.savefig(file_path_fit+store_mcmc_fit)\n",
    "        \n",
    "        plt.show(block=False)    \n",
    "        time.sleep(0.5)\n",
    "        plt.close(fig_lc)\n",
    "        \n",
    "    #---------- CREATE CORNER PLOTS ---------- \n",
    "    true_params = [star.depth, star.b, None, star.smass, star.rs, 1.0, star.P, 0.0]\n",
    "    if corner_plot == True:\n",
    "        res_labels = ['Depth', 'b', r'$\\sigma$', r'$M_{*} [M_{\\odot}]$', r'$R_{*} [R_{\\odot}]$', \n",
    "              r'$f_{0}$', 'P [d]', r'$t_c$']\n",
    "        #plt.clf()\n",
    "        fig_corner = corner.corner(samples, weights = None, labels = res_labels, quantiles=[0.16, 0.5, 0.84], \n",
    "                            truths = true_params, show_titles = True, title_args={\"fontsize\": 12}, \n",
    "                        plot_contours=True, plot_datapoints=True) \n",
    "        \n",
    "        if corner_store == True:\n",
    "            file_path = '/Users/mbadenas/Documents/Master UAB/Tesis UAB/TFM2018/results/corner/'\n",
    "            store_corner = \"corner\"+str(star.kepid)+\"_st\"+str(steps)+\"_trans\"+str(num_trans+1)+\".png\"\n",
    "            fig_corner.savefig(file_path+store_corner)\n",
    "        \n",
    "        plt.suptitle('Corner Plot for KID'+str(star.kepid), fontsize = 20)\n",
    "        plt.show(block=False)    \n",
    "        time.sleep(0.5)\n",
    "        plt.close(fig_corner)\n",
    "    \n",
    "     #---------- MCMC CHECKS ----------\n",
    "    af = sampler.acceptance_fraction  #As a rule of thumb, the acceptance fraction (af) should be between 0.2 and 0.5. \n",
    "    #If af < 0.2 decrease the a parameter. If af > 0.5 increase the a parameter. \n",
    "    print(\"Mean acceptance fraction:\", np.mean(af))\n",
    "    print(\"Acceptance fraction: {0:.2f} %\".format(100 * np.mean(sampler.acceptance_fraction)))\n",
    "    \n",
    "    if burnin_plot == True: \n",
    "        create_burnin_plot(star, burnin_store, steps, num_trans, sampler, true_params)\n",
    "            \n",
    "    return (period_distribution, results_mcmc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_burnin_plot(star, storePlot, steps, num_trans, sampler, true_params):\n",
    "    #plt.clf()\n",
    "    fig_b, axes = plt.subplots(8, 1, sharex=True, figsize=(8, 9))\n",
    "    axes[0].plot(sampler.chain[:, :, 0].T, ls='dotted', color = \"xkcd:sky blue\") #depth = 0\n",
    "    axes[0].set_ylabel(r'Depth'); axes[0].axhline(true_params[0], color='red')\n",
    "    axes[1].plot(sampler.chain[:, :, 1].T,'.', ls='dotted', color=\"xkcd:sky blue\")\n",
    "    axes[1].set_ylabel(r'$b$'); axes[1].axhline(true_params[1], color='red')\n",
    "    axes[2].plot((sampler.chain[:, :, 2]).T, ls='dotted', color=\"xkcd:sky blue\")\n",
    "    axes[2].set_ylabel(r'$\\sigma$');\n",
    "    axes[3].plot((sampler.chain[:, :, 3]).T, ls='dotted', color=\"xkcd:sky blue\")\n",
    "    axes[3].set_ylabel(r'$M_{*} [M_{\\odot}]$'); axes[3].axhline(true_params[3], color='red')\n",
    "    axes[4].plot((sampler.chain[:, :, 4]).T, ls='dotted', color=\"xkcd:sky blue\")\n",
    "    axes[4].set_ylabel(r'$R_{*} [R_{\\odot}]$'); axes[4].axhline(true_params[4], color='red')\n",
    "    axes[5].plot((sampler.chain[:, :, 5]).T, ls='dotted', color=\"xkcd:sky blue\")\n",
    "    axes[5].set_ylabel('$f_{0}$'); axes[5].axhline(true_params[5], color='red')\n",
    "    axes[6].plot((sampler.chain[:, :, 6]).T, ls='dotted',color=\"xkcd:sky blue\")\n",
    "    axes[6].set_ylabel(\"$P [d]$\"); axes[6].axhline(true_params[6], color='red')\n",
    "    axes[7].plot((sampler.chain[:, :, 7]).T, ls='dotted',color=\"xkcd:sky blue\")\n",
    "    axes[7].set_ylabel(\"$t_{c}$\");\n",
    "    axes[7].set_xlabel(\"Step number\")\n",
    "    fig_b.tight_layout(h_pad=0.0)\n",
    "    plt.show(block=False)    \n",
    "    \n",
    "    if storePlot == True:\n",
    "        filepath = '/Users/mbadenas/Documents/Master UAB/Tesis UAB/TFM2018/results/burnin/'\n",
    "        store_steps= \"steps\"+str(star.kepid)+\"_st\"+str(steps)+\"_trans\"+str(num_trans+1)+\".png\"\n",
    "        fig_b.savefig(filepath+store_steps)\n",
    "        \n",
    "    time.sleep(0.5)\n",
    "    plt.close(fig_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transit Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Amplification of transit duration by:\", amplify)\n",
    "\n",
    "sc = 58.0  #sc = 58 sec\n",
    "tKep = sc/60/60/24  # sc in days\n",
    "three_jup_rad = 0.2055 #2 RJup = 0.2055 Solar Radii    \n",
    "G = 6.6730e-11"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MCMC Initialization Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nwalkers = 100\n",
    "steps = 140\n",
    "id_mcmc = [\"Depth:\", \"Impact parameter (b):\", \"sigma:\", \"Stellar Mass (Ms):\",\n",
    "           \"Stellar Radius (Rs):\", \"Out-of-transit flux (f0):\", \"Orbital Period (P):\", \n",
    "           \"Time of transit (tc):\", \"Planetary Radius (Rp):\", \"Rs_a:\"]\n",
    "\n",
    "header_mcmc = \"This file shows the 50% percentile and the +- 1 sigma error interval of the parameters.\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.close(\"all\")\n",
    "s1 = set(stars_wo_transits)\n",
    "ugly_stars = {5009743, 8802165, 9578686, 10864656, 11259686, 11133306}\n",
    "\n",
    "for target in targets:\n",
    "    if (target.kepid not in s1) and (target.kepid not in ugly_stars): #only consider targets with observed transits\n",
    "        plt.close(\"all\")\n",
    "        print(\"\\n******** KID\"+str(target.kepid)+\" ********\")\n",
    "        transit_range = (amplify*target.duration)/2 # In days \n",
    "        missed_trans = set(target.ind_missed_transits)\n",
    "        print(\"Transit range [d]:\", transit_range)\n",
    "        \n",
    "        fit_results = []\n",
    "        period_distributions = []\n",
    "        MCMC_transits = []\n",
    "        \n",
    "        for i in range(len(target.transit_times)):\n",
    "            if (i not in missed_trans): #only consider the observed transits, not the missing ones \n",
    "                print(\"\\t TRANSIT \"+str(i+1))\n",
    "                dt_trans = target.ttrans[target.trans_id==i]-target.transit_times[i]\n",
    "                f_trans = target.ftrans[target.trans_id==i] \n",
    "                oot = np.abs(dt_trans)>=transit_range\n",
    "                iit = np.abs(dt_trans)<transit_range\n",
    "                d = 1-np.mean(f_trans[iit])\n",
    "                print(\"\\t\\td = {0:0.5f}, 1-min(f) = {1:0.5f}\".format(d,1-min(f_trans)))\n",
    "                error_trans = np.std(f_trans[oot])\n",
    "                print(\"\\t\\tError transit = \"+str(i+1)+\": \"+str(error_trans))\n",
    "                \n",
    "                res_fit = run_transit_routine(target, dt_trans, f_trans, error_trans, i)\n",
    "                period_res, mcmc_res = run_mcmc(target, dt_trans, f_trans, error_trans, i, res_fit, \n",
    "                                                True, True, True, True, True, True)\n",
    "                \n",
    "                fit_results.append(res_fit)\n",
    "                period_distributions.append(period_res)\n",
    "                MCMC_transits.append(mcmc_res)\n",
    "                \n",
    "                locs_P_trans = '/Users/mbadenas/Documents/Master UAB/Tesis UAB/TFM2018/results/period_distributions/'\n",
    "                fname_P_trans = str(target.kepid)+\"_st\"+str(steps)+\"_Pdist_trans\"+str(i+1)+\".txt\"\n",
    "                np.savetxt(locs_P_trans+fname_P_trans, np.transpose(period_res), fmt = \"%0.15f\")\n",
    "                \n",
    "                locs_MCMC = '/Users/mbadenas/Documents/Master UAB/Tesis UAB/TFM2018/results/MCMC_results/'\n",
    "                fname_MCMC = str(target.kepid)+\"_st\"+str(steps)+\"_MCMCres\"+str(i+1)+\".txt\"\n",
    "                np.savetxt(locs_MCMC+fname_MCMC, np.column_stack((id_mcmc, mcmc_res)), header = header_mcmc, \n",
    "                           delimiter=\" \", fmt=\"%s\")\n",
    "                \n",
    "            else:\n",
    "                fit_results.append(0)  \n",
    "                period_distributions.append(0)\n",
    "                MCMC_transits.append(0)\n",
    "        \n",
    "        target.res_transfit = fit_results\n",
    "        target.P_distribution = period_distributions\n",
    "        target.MCMC_transits = MCMC_transits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8,8))\n",
    "plt.subplot(311)\n",
    "counts, bins, patches = plt.hist(period_data, density = False, weights = None, histtype='stepfilled',alpha=0.4) #bins = Edges of the bins\n",
    "pos_highest_bin = np.argmax(counts)\n",
    "print(len(period_data))\n",
    "print(\"Bin {0:s}, which contains periods between {1:.2f} and {2:0.2f} days, is \\\n",
    "more likely to contain the true period.\".format(str(pos_highest_bin+1),bins[pos_highest_bin],bins[pos_highest_bin+1]))\n",
    "\n",
    "mask_period = (period_data >= bins[pos_highest_bin]) & (period_data <= bins[pos_highest_bin+1])\n",
    "period_candidates = period_data[mask_period == True]\n",
    "print(len(period_candidates))\n",
    "\n",
    "plt.subplot(312)\n",
    "counts_c, bins_c, patches_c = plt.hist(period_candidates, density = False, weights = None, histtype='stepfilled',alpha=0.4) #bins = Edges of the bins\n",
    "plt.xlabel('Period [days]'); \n",
    "\n",
    "pos_highest_bin_c = np.argmax(counts_c)\n",
    "mask_period_c = (period_candidates >= bins_c[pos_highest_bin_c]) & (period_candidates <= bins_c[pos_highest_bin_c+1])\n",
    "period_candidates_c = period_candidates[mask_period_c == True]\n",
    "\n",
    "plt.subplot(313)\n",
    "counts_cc, bins_cc, patches_cc = plt.hist(period_candidates_c, density = False, weights = None, histtype='stepfilled',alpha=0.4) #bins = Edges of the bins\n",
    "\n",
    "store_hist= \"hist\"+str(target_id)\n",
    "plt.savefig(store_hist+'.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lnlike(theta, timeLC, fluxLC, errorLC, allfixed):\n",
    "    \"\"\"\n",
    "    theta[0] = pdepth = (Rp/Rs)^2\n",
    "    theta[1] = pb = the impact parameter\n",
    "    theta[2] = pt0 = the time of transit\n",
    "    theta[3] = sigma = an additional white noise term\n",
    "    theta[4] = u1 + u2 = sum of LD coefficients\n",
    "    theta[5] = pmass = the mass of the star (controlled via gaussian prior)\n",
    "    theta[6] = pradius = the radius of the star (controlled via gaussian prior)\n",
    "    theta[7] = f0 = the out of eclipse flux\n",
    "     Gaussian prior: We assume that the parameter we want to fit \n",
    "    is constrained within the range centered on the maximum value of a \n",
    "    Gaussian distribution. \n",
    "    \n",
    "    \"\"\"   \n",
    "    pdepth, pb, pt0, sigma, sumLD, pmass, pradius, f0 = theta\n",
    "    period, ecc, mass, masserr, radius, radiuserr, diffLD, tKep = allfixed\n",
    "    \n",
    "    u1 = 0.5*(sumLD+diffLD) \n",
    "    u2 = sumLD-u1\n",
    "    \n",
    "    s = transit.System(transit.Central(mu1 = u1, mu2 = u2, mass = pmass, radius = pradius))\n",
    "    body = transit.Body(r = np.sqrt(pdepth)*pradius, period = period, t0 = pt0, b = np.abs(pb), e = ecc)\n",
    "    s.add_body(body)\n",
    "    \n",
    "    sigma2 = errorLC**2 + sigma**2\n",
    "    ftheo = s.light_curve(timeLC, texp = tKep, tol = 10e-2, maxdepth = 4)\n",
    "    ftheo = ftheo - 1.0 + f0\n",
    "    \n",
    "    return -0.5*(np.sum(((fluxLC-ftheo)**2)/sigma2 - np.log(1.0/sigma2)) +\n",
    "                 ((pmass-mass)/masserr)**2 + \n",
    "                 ((pradius-radius)/radiuserr)**2) # Chi Squared\n",
    "\n",
    "def lnprior(theta): \n",
    "    # This function ensures that our best estimates make physical sense.\n",
    "    pdepth, pb, pt0, sigma, sumLD, pmass, pradius, f0 = theta\n",
    "    if (0.2 < sumLD < 1.0) and (0 <= pb <0.9) and (0 <= sigma) and (pradius > 0) and (pdepth > 0) and (pmass > 0):\n",
    "        return 0.0 \n",
    "    return -np.inf\n",
    "\n",
    "def lnprob(theta, timeLC, fluxLC, errorLC, allfixed):\n",
    "    lp = lnprior(theta)\n",
    "    if not np.isfinite(lp):\n",
    "        return -np.inf\n",
    "    return lp + lnlike(theta, timeLC, fluxLC, errorLC, allfixed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_fit(system):\n",
    "    \n",
    "    perTP_no_Units = np.float(np.copy(system.perTP))\n",
    "    duration_no_units = np.float(np.copy(system.durationTP))\n",
    "\n",
    "    allfixed = [perTP_no_Units, system.eccen, system.smass, system.smass_err, \n",
    "                system.rs, system.rs_err, system.diffld, tKep]\n",
    "    \n",
    "    nll = lambda *args: -lnprob(*args)\n",
    " \n",
    "    # Minimization of the function \"nll\"\n",
    "    result = op.minimize(nll, [1.2*system.depthTP, 0.0, 0.0, 0.0, system.u1+system.u2, system.smass, system.rs, 0.0], \n",
    "                             args = (np.array(system.folded_time), np.array(system.folded_flux), \n",
    "                                     system.rms_ootTP, allfixed),\n",
    "                             options = {'disp': True}, method  ='Nelder-Mead')\n",
    "    \n",
    "    # Store best estimates in \"result[\"x\"]\n",
    "    depth_ml, b_ml,  t0_ml, sigma_ml, sumLD_ml, mass_ml, radius_ml, f0_ml  = result[\"x\"]\n",
    "\n",
    "    system.optimize_loop1 = result[\"x\"]\n",
    "\n",
    "    # Readjust LD coefficients. \n",
    "    u1_ml = 0.5*(sumLD_ml + system.diffld)\n",
    "    u2_ml = sumLD_ml - u1_ml\n",
    "\n",
    "    # Compute each transit LC integrated over a Kepler long cadence exposure time \n",
    "    # with the result derived from optimization and plot theoretical model and observed data.\n",
    "\n",
    "    s = transit.System(transit.Central(mu1 = u1_ml, mu2 = u2_ml, mass = mass_ml, radius = radius_ml))\n",
    "\n",
    "    body = transit.Body(r = np.sqrt(depth_ml)*radius_ml, period = perTP_no_Units, t0 = t0_ml, \n",
    "                            b = b_ml, e = system.eccen)\n",
    "\n",
    "    s.add_body(body)\n",
    "    t_theory = np.arange(-1.0, 1.0, tKep)\n",
    "    f_theory = s.light_curve(t_theory, texp = tKep, tol = 1e-2, maxdepth = 5)\n",
    "    f_theory = f_theory - 1.0 + f0_ml\n",
    "    \n",
    "    fig = plt.figure()\n",
    "    plt.plot(24.*system.folded_time, system.folded_flux,'.') \n",
    "    plt.plot(24.*t_theory, f_theory,'.')\n",
    "    plt.title('KID' + str(system.kepid))\n",
    "    plt.xlabel('Time from midtransit [hours]')\n",
    "    plt.ylabel('De-trended Flux')\n",
    "    plt.xlim([-duration_no_units*24., duration_no_units*24.])\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sc = 58.0  #sc = 58 sec -> \n",
    "tKep = sc*(1./60.)*(1./60.)*(1./24.)  # sc in days\n",
    "\n",
    "for system in targets:\n",
    "    if system.num_planets == 1:\n",
    "        print \"KID\"+str(system.kepid)+':'\n",
    "        find_best_fit(system)\n",
    "        \n",
    "        print \"Depth:\", system.optimize_loop1[0]\n",
    "        print \"Impact parameter:\", system.optimize_loop1[1],\"vs Kepler reported value:\", system.impact\n",
    "        print \"Initial transit time (Phase-folded LC):\", system.optimize_loop1[2]\n",
    "        print \"Mass of the star (Solar units):\", system.optimize_loop1[5],\"vs Kepler reported value:\", system.smass\n",
    "        print \"Radius of the star (Solar units):\",  system.optimize_loop1[6], \"vs Kepler reported value:\", system.rs\n",
    "        print \"Out-of-transit flux\",  system.optimize_loop1[7],\"\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identify Transits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_transits(system):\n",
    "    \n",
    "    t_initial = min(system.time_BKJD)\n",
    "    t_end = max(system.time_BKJD)\n",
    "    t0 = system.t\n",
    "    \n",
    "    n_min = int((t_initial-t0)/system.per)\n",
    "    n_max = int((t_end-t0)/system.per+1.)\n",
    "    n = np.arange(n_min, n_max)\n",
    "\n",
    "    transit_times = t0+n*system.per\n",
    "    transit_times = transit_times[transit_times>t_initial] \n",
    "    transit_times = transit_times[transit_times<t_end]\n",
    "    system.transits = transit_times\n",
    "    \n",
    "    #print \"Transits should occur at:\", system.transits,\"\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fold(system):\n",
    "    #Returns time values ranging between -\"transit_range\" to +\"transit_range\". Data points \n",
    "    #which occur exactly at ``phase`` or an integer multiple of `phase + n*period` have time value 0.0. \n",
    "    #Note: transit window = 2*transit_range\n",
    "    \n",
    "    phase = system.time0bk\n",
    "    transit_range = (system.duration)/2.\n",
    "    print \"Transit range:\", transit_range\n",
    "    \n",
    "    fold_time = ((system.time_BKJD-phase+transit_range*system.per)/system.per)%1-transit_range\n",
    "    sorted_args = np.argsort(fold_time)   \n",
    "    system.foldedTime = fold_time[sorted_args]\n",
    "    system.flux = system.flux[sorted_args]\n",
    "    system.flux_err = system.flux_err[sorted_args] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for target in targets:\n",
    "        print(\"\\n******\\t\"+str(target.kepid)+\"******\")\n",
    "        \n",
    "        print(len(target.time_BKJD))\n",
    "        total_days = target.time_BKJD.iloc[-1]-target.time_BKJD.iloc[0]\n",
    "        one_day = np.abs(int(len(target.time_BKJD)/total_days))\n",
    "        sensitivity = 2\n",
    "        min_peak_dist = one_day*sensitivity\n",
    "        target.peaks = run_peak_filter(target, min_peak_dist, plot = True)\n",
    "        \n",
    "        num_peaks = len(target.peaks[:,2])\n",
    "         \n",
    "        final_peaks = np.copy(target.peaks)\n",
    "        tpeaks = [None]*num_peaks\n",
    "        fpeaks = [None]*num_peaks\n",
    "        fpeaks_err = [None]*num_peaks\n",
    "        \n",
    "        #Explore peak-by-peak and discard those which are too noisy or unclear\n",
    "        for i in range(num_peaks):\n",
    "            pos_peak, t_peak, f_peak = int(target.peaks[i,0]), int(target.peaks[i,1]), target.peaks[i,2]\n",
    "            if (i!=num_peaks-1): \n",
    "                dist_from_transit = int((target.peaks[i+1,0]-pos_peak)/2) #todo: average separation b/w peaks\n",
    "            else: \n",
    "                dist_from_transit = int((pos_peak-target.peaks[i-1,0])/2)\n",
    "            \n",
    "            if (dist_from_transit/one_day > 1.0): dist_from_transit = int(one_day)\n",
    "            dist_from_transit = int(one_day)\n",
    "            print(\"Transit range [d]:\", dist_from_transit/one_day)\n",
    "            \n",
    "            t_zoom = (target.time_BKJD[pos_peak-dist_from_transit:pos_peak+dist_from_transit]).values\n",
    "            f_zoom = (target.flux[pos_peak-dist_from_transit:pos_peak+dist_from_transit]).values\n",
    "            f_err_zoom = (target.flux_err[pos_peak-dist_from_transit:pos_peak+dist_from_transit]).values\n",
    "\n",
    "            corr_f_zoom = sig.medfilt(f_zoom, 9)\n",
    "            time_max_peak = np.argmin(corr_f_zoom)\n",
    "            tc = t_zoom[time_max_peak]\n",
    "\n",
    "            # Subtract time offset\n",
    "            t_zoom-=tc\n",
    "\n",
    "            #Select [-1,1] interval\n",
    "            mask_int = (t_zoom > -1) & (t_zoom < 1)\n",
    "            t_zoom_mask = t_zoom[mask_int==True]\n",
    "            corr_f_zoom_mask = corr_f_zoom[mask_int==True]\n",
    "            corr_f_zoom_err_mask = f_err_zoom[mask_int==True]\n",
    "\n",
    "            tpeaks[i] = t_zoom_mask \n",
    "            fpeaks[i] = corr_f_zoom_mask \n",
    "            fpeaks_err[i] = corr_f_zoom_err_mask \n",
    " \n",
    "            #print(np.median(corr_f_zoom_mask),np.mean(corr_f_zoom_mask),np.std(corr_f_zoom_mask))\n",
    "\n",
    "            \"\"\"\n",
    "            if (int(np.mean(corr_f_zoom_mask))>1):\n",
    "                print('\\tPeak {:s} is unclear or too noisy -- disregard it.'.format(str(i+1)))\n",
    "                final_peaks[i,:]=0.0\n",
    "                tpeaks[i], fpeaks[i], fpeaks_err[i] = 0, 0, 0\n",
    "            \"\"\"\n",
    "            plt.figure()\n",
    "            plt.title('Transit %s'%str(i+1))\n",
    "            plt.plot(t_zoom_mask,corr_f_zoom_mask,'.')\n",
    "            plt.show(block=False)\n",
    "            time.sleep(1)\n",
    "            plt.close()\n",
    "                \n",
    "        bad_peaks = (final_peaks==0.0).all(1)\n",
    "        target.peaks = final_peaks[bad_peaks == False]\n",
    "        bad_peaks_indx = np.where(bad_peaks)[0]\n",
    "\n",
    "        for index in sorted(bad_peaks_indx, reverse=True):\n",
    "            del tpeaks[index]\n",
    "            del fpeaks[index]\n",
    "            del fpeaks_err[index]\n",
    "\n",
    "        target.tpeaks  = tpeaks\n",
    "        target.fpeaks = fpeaks\n",
    "        target.fpeaks_err = fpeaks_err\n",
    "\n",
    "        print(\"Nº of peaks (updated):\", len(target.peaks[:,0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def run_peak_filter(star, mpd, plot):\n",
    "    pos_drops, _ = sig.find_peaks(-star.flux, distance=mpd)\n",
    "    \n",
    "    flux_drops = star.flux[pos_drops]\n",
    "    drops = np.column_stack((pos_drops, flux_drops))\n",
    "    \n",
    "    print(\"Nº of peaks (before mask):\",len(flux_drops))\n",
    "    time_max_flux_drop = (flux_drops).idxmin(axis=None, skipna=True)\n",
    "    depth_guess = 1-min(flux_drops)\n",
    "        \n",
    "    mask_drops = min(flux_drops)+depth_guess*(1/2)\n",
    "    keep_drops = drops[:,1]<=mask_drops\n",
    "        \n",
    "    print(\"\\tRemove peaks > than\", mask_drops)\n",
    "    drops_mask = drops[keep_drops==True]\n",
    "    print(\"Nº of peaks (after mask):\",len(drops_mask[:,1]))\n",
    "    \n",
    "    final_peaks = np.column_stack((drops_mask[:,0],star.time_BKJD[drops_mask[:,0]].values, drops_mask[:,1]))\n",
    "    \n",
    "    #Check if the first peak is too close to the start or end of the cadence \n",
    "    pos_peak_i = int(final_peaks[0,0])\n",
    "    pos_peak_f = int(final_peaks[-1,0])\n",
    "    \n",
    "    dist_transit_i = (final_peaks[1,0]-final_peaks[0,0])/2\n",
    "    dist_transit_f = (final_peaks[-1,0]-final_peaks[-2,0])/2\n",
    "    \n",
    "    if (pos_peak_i-dist_transit_i < 0): \n",
    "        final_peaks = np.delete(final_peaks, 0, axis=0)\n",
    "        \n",
    "    if (pos_peak_f+dist_transit_f>star.time_BKJD.iloc[-1]):  \n",
    "        final_peaks = np.delete(final_peaks, -1, axis=0)\n",
    "    \n",
    "    #Print the updated number of peaks\n",
    "    print(\"Nº of peaks (after checking ends):\", len(final_peaks[:,0]))\n",
    "    \n",
    "    if (plot == True):\n",
    "        plt.figure(figsize=(15,10))\n",
    "        plt.title('KID'+str(star.kepid))\n",
    "        plt.plot(star.time_BKJD, star.flux,'.',star.time_BKJD[drops[:,0]],drops[:,1],'ro')\n",
    "        plt.subplot(2,1,1)\n",
    "        plt.ylabel('Flux'); plt.xlabel('Time BKJD')\n",
    "        plt.plot(star.time_BKJD, star.flux,'.',star.time_BKJD[drops[:,0]],drops[:,1],'ro')\n",
    "        plt.subplot(2,1,2)\n",
    "        plt.ylabel('Flux'); plt.xlabel('Time BKJD')\n",
    "        plt.plot(star.time_BKJD, star.flux,'.',final_peaks[:,1],final_peaks[:,2],'ro')\n",
    "        plt.axhline(y=mask_drops, color='k', linestyle='-')\n",
    "        plt.show(block=False)\n",
    "        time.sleep(1)\n",
    "        plt.close()\n",
    "        \n",
    "    return(final_peaks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fold(star):\n",
    "    #Returns time values ranging between -\"transit_range\" to +\"transit_range\". Data points \n",
    "    #which occur exactly at ``phase`` or an integer multiple of `phase + n*period` have time value 0.0. \n",
    "    #Note: transit window = 2*transit_range\n",
    "    \n",
    "    phase = star.time0bk\n",
    "    transit_range = (star.duration)/2.\n",
    "    print(\"Transit range:\", transit_range)\n",
    "    \n",
    "    fold_time = ((star.time_BKJD-phase+transit_range*star.P)/star.P)%1-transit_range\n",
    "    sorted_args = np.argsort(fold_time)   \n",
    "    #star.foldedTime = fold_time[sorted_args]\n",
    "    #system.flux = system.flux[sorted_args]\n",
    "    #system.flux_err = system.flux_err[sorted_args] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def colTrans(system):\n",
    "    color_code = plt.figure(figsize=(17,5))\n",
    "    ax1 = plt.subplot(121)\n",
    "    ax2 = plt.subplot(122)\n",
    "    \n",
    "    for i in range(0,len(system.transits)):\n",
    "        transitBool = (system.flag == i)\n",
    "        \n",
    "        if i % 2 == 0: #even transit\n",
    "            ax1.plot(system.t_trans[transitBool], system.f_trans[transitBool], '.', color = 'red', label = 'Even')\n",
    "            ax2.plot(system.dt[transitBool], system.f_trans[transitBool],'.', color = 'red', label = 'Even')\n",
    "        else:\n",
    "            ax1.plot(system.t_trans[transitBool], system.f_trans[transitBool], '.', color = 'green', label = 'Odd')\n",
    "            ax2.plot(system.dt[transitBool], system.f_trans[transitBool],'.', color = 'green', label = 'Odd')\n",
    "    \n",
    "    ax1.legend(); ax2.legend(); \n",
    "    ax1.set_title('KID'+ str(system.kepid), fontsize = 14); \n",
    "    ax2.set_title('Folded LC for KID'+ str(system.kepid), fontsize = 14)\n",
    "    ax1.set_ylabel('Normalized Flux');\n",
    "    ax1.set_xlabel('BJD-2454833 (days) '); ax2.set_xlabel('Time from midtransit (days)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "def export_folded_lc(system, fraction):\n",
    "    len_file = len(system.f_trans)\n",
    "    cut = random.sample(zip(system.f_trans, system.f_trans_err, system.dt), int(fraction*len_file/100))\n",
    "    cut_flux, cut_flux_err, cut_time = zip(*cut)\n",
    "    \n",
    "    system.dt = np.array(cut_time) #use np.array to convert from tuple to array\n",
    "    system.f_trans = np.array(cut_flux)\n",
    "    system.f_trans_err = np.array(cut_flux_err)\n",
    "    \n",
    "    cut_fold_lc = pd.DataFrame(OrderedDict({'Phase': cut_time, 'Flux': cut_flux, 'Flux_Err': cut_flux_err}))\n",
    "     \n",
    "    np.savetxt('/Users/mbadenas/Documents/Master UAB/Tesis UAB/folded_LC/cut'+str(fraction) \\\n",
    "               +'_fold_KID'+str(system.kepid)+'.txt', \n",
    "               cut_fold_lc.values, fmt='%f', delimiter=\"\\t\", header=\"Phase\\t\\tFlux (normalized)\\t\\tFlux error\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cut_fraction = 50 #in %. If 100, the entire light curve is used.\n",
    "one_planet = 0\n",
    "\n",
    "for system in targets:\n",
    "    if system.num_planets==1:\n",
    "        find_transits(system)\n",
    "        fold(system)\n",
    "        transit_window(system)\n",
    "        \n",
    "        fig = plt.figure(figsize=(17,5))\n",
    "        ax1 = plt.subplot(121)\n",
    "        ax2 = plt.subplot(122)\n",
    "    \n",
    "        ax1.plot(system.time_BKJD, system.flux,'.')\n",
    "        ax1.plot(system.transits, np.ones(len(system.transits))*min(system.flux),'ro')  \n",
    "        ax1.set_xlabel('BJD-2454833 (days)'); \n",
    "        ax1.set_ylabel('Normalized Flux'); \n",
    "        ax1.set_title('KID'+str(system.kepid)); \n",
    "        \n",
    "        ax2.plot(system.foldedTime, system.flux,'.')\n",
    "        ax2.set_xlabel('Time from midtransit (days)'); \n",
    "        ax2.set_ylabel('Normalized Flux')\n",
    "        ax2.set_title('Folded LC for '+str(system.kepid)) \n",
    "        \n",
    "        colTrans(system)\n",
    "        export_folded_lc(system, cut_fraction)\n",
    "        \n",
    "        one_planet += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Theoretical model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Todo: standard dev of out-of-transit flux for each identified transit "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

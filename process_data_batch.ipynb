{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# III - `Process Data`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config IPython.matplotlib.backend = \"retina\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rcParams\n",
    "rcParams['figure.figsize'] = 10, 7\n",
    "rcParams[\"figure.dpi\"] = 150\n",
    "rcParams[\"savefig.dpi\"] = 150\n",
    "\n",
    "import transit\n",
    "import emcee\n",
    "import corner\n",
    "\n",
    "import astroML \n",
    "#from astroML.plotting import setup_text_plots\n",
    "#setup_text_plots(fontsize=14, usetex=True)\n",
    "\n",
    "import astropy\n",
    "from astropy import constants as const\n",
    "from astropy import units as u\n",
    "from astropy.modeling import models, fitting\n",
    "from astropy.io import fits\n",
    "from astropy.table import Table\n",
    "\n",
    "import scipy.optimize as op\n",
    "import scipy.signal as sig\n",
    "from scipy.signal import argrelextrema, medfilt\n",
    "from random import uniform, randrange\n",
    "\n",
    "import kplr\n",
    "from kplr.ld import get_quad_coeffs\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_file = '/Users/mbadenas/Documents/Master UAB/Tesis UAB/TFM2018/clean_bat_files/LC_p13point5up/'\n",
    "path_mergedLC = '/Users/mbadenas/Documents/Master UAB/Tesis UAB/TFM2018/merge_light_curves/LC_p13point5up_merged/'\n",
    "\n",
    "properties_sample = pd.read_csv(path_file+'all_targets_P13point5up.csv', sep=',', comment='#')\n",
    "targets = pd.read_csv(path_file + 'kepler_id.txt',delimiter=',', dtype=int, header=None, names=['kepid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(targets, properties_sample, on=['kepid'], how='inner') \n",
    "sc_data = df.drop_duplicates('kepid') #remove duplicates (some systems have both sc and lc LC)\n",
    "\n",
    "print(\"Check files:\")\n",
    "\n",
    "if (len(targets) != len(properties_sample)):\n",
    "    print(\"*Lengths don't match:\", len(targets), len(properties_sample))\n",
    "    print(\"\\tSome systems have both sc and lc data! Remove duplicates.\")\n",
    "\n",
    "if (len(sc_data) == len(targets)):\n",
    "    print(\"*Lengths match:\", len(sc_data), len(targets))\n",
    "    print('\\tDuplicates have been removed.\\n A total of {} systems have short-cadence LC with SN > 7.1 for their first transit'.format(len(sc_data)))\n",
    "    \n",
    "sc_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the Systems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class System:    \n",
    "    def __init__(self, kepid, rs, rs_err, smass, smass_err, teff, logg, feh, srho,\n",
    "                time_BKJD, flux, flux_err, \n",
    "                P, depth, b, duration, u1, u2, diffld, num_planets, incl, eccen, dor, sma,\n",
    "                rp, rp_err, teq, mp, peaks, tpeaks, fpeaks, fpeaks_err, duration_fit):\n",
    "        \n",
    "        \"\"\"****** Kepler Reported Stellar Parameters ******\"\"\"\n",
    "        self.kepid = kepid\n",
    "        self.rs = rs # [Solar radii]. \n",
    "        self.rs_err = rs_err\n",
    "        self.smass = smass # [Solar mass]\n",
    "        self.smass_err = smass_err\n",
    "        \n",
    "        self.teff = teff;     \n",
    "        self.logg = logg; # Stellar Surface Gravity [log10(cm/s**2)]  \n",
    "        self.feh = feh;   \n",
    "        self.srho = srho; #g/cm3\n",
    "        \n",
    "        \"\"\"****** LC parameters ******\"\"\"\n",
    "        self.time_BKJD = time_BKJD\n",
    "        self.flux = flux\n",
    "        self.flux_err = flux_err\n",
    "        \n",
    "        \"\"\"****** Transit Parameters ******\"\"\"\n",
    "        self.P = P;            \n",
    "        self.depth = depth;  \n",
    "        self.b = b; \n",
    "        self.duration = duration; \n",
    "        self.u1 = u1; \n",
    "        self.u2 = u2\n",
    "        self.diffld = 0.0\n",
    "        self.num_planets = num_planets\n",
    "        self.incl = incl #[º]\n",
    "        self.eccen = 0.0\n",
    "        self.dor = dor #Planet-Star Distance over Star Radius\n",
    "        self.sma = sma #Orbital semi-major axis [AU]\n",
    "        \n",
    "        #self.depth = rprs ** 2 \n",
    "            # Transit depth in absolute terms. To 1st order (assuming stellar disk has uniform brightness and \n",
    "            # neglecting any flux coming from planet), the ratio X of the observed change in flux, Delta(F), \n",
    "            # to that of the stellar flux F is: X = (Rp/Rs)^2 = depth.\n",
    "                   \n",
    "        \"\"\"****** Planetary Parameters ******\"\"\"\n",
    "        self.rp = rp # [Earth radii]. This is \"prad\"  in the original file\n",
    "        self.rp_err = rp_err\n",
    "        self.teq = teq\n",
    "        self.mp = 2.69*(rp)**(0.93) #Weiss & Marcy rel'n. It requires Rp in Earth radii\n",
    "        \n",
    "        \"\"\"****** Internal Variables ******\"\"\"\n",
    "        self.peaks = np.empty(0)\n",
    "        self.tpeaks = np.empty(0)\n",
    "        self.fpeaks = np.empty(0)\n",
    "        self.fpeaks_err = np.empty(0)\n",
    "        \n",
    "        self.duration_fit = duration_fit\n",
    "    def Print(self):\n",
    "        print(\"System {}\".format(self.kepid))\n",
    "        print('rho={0:0.3f}, logg={1:0.3f} [log10(cm/s**2)], a={2:0.3f} [AU]'.format(self.srho, self.logg,self.sma))\n",
    "        print(\"Impact parameter b:\",self.b)\n",
    "        print(\"Depth {0:0.2f} (or {1:0.2f} in ppm)\".format(self.depth, self.depth*1e6))\n",
    "        print(\"u1: {0:0.3f}, u2: {1:0.3f}\".format(self.u1,self.u2))\n",
    "        print(\"Temperature [K]:\",self.teff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Characterize the Systems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some initialization functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bjd_ref = 2454833\n",
    "\n",
    "def quadraticLD(T, G, FEH): \n",
    "    \"\"\"Confirm the quadratic LD coefficients with a model from Claret & Bloemen (2011).\n",
    "    Use the Claret coefficients instead.\"\"\"\n",
    "    mu1, mu2 = get_quad_coeffs(T, G, FEH)\n",
    "    return (mu1, mu2)\n",
    "\n",
    "def fetchLC(name):\n",
    "    id_kep = \"%.0f\" % name\n",
    "    lc = path_mergedLC+('KID'+id_kep+'.txt')\n",
    "    df = pd.read_csv(lc, sep=\"\\t\", skiprows=1, header=None, names=[\"Time BKJD\", \"Flux\", \"Flux_Err\"])\n",
    "    y = df['Flux']\n",
    "    yerr = df['Flux_Err']\n",
    "    x = df['Time BKJD']\n",
    "    #print(np.median(y),np.mean(y),np.std(y))\n",
    "    return (y, yerr, x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the planet+star system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = []\n",
    "\n",
    "for row in sc_data.itertuples(index = True, name='Pandas'):\n",
    "    kepid = getattr(row, \"kepid\")\n",
    "    fluxLC, fluxLC_err, timeLC_BKJD = fetchLC(kepid)\n",
    "\n",
    "    ## Store the stellar parameters\n",
    "    rs = getattr(row, \"koi_srad\") #solar radii\n",
    "    rs_errPos = getattr(row, \"koi_srad_err1\"); rs_errNeg = getattr(row, \"koi_srad_err2\")\n",
    "    rs_err = np.abs((rs_errPos+rs_errNeg)/2.)\n",
    "    \n",
    "    smass = getattr(row, \"koi_smass\")\n",
    "    smass_errPos = getattr(row, \"koi_smass_err1\"); smass_errNeg = getattr(row, \"koi_smass_err2\")\n",
    "    smass_err = np.abs((smass_errPos+smass_errNeg)/2.)\n",
    "    \n",
    "    teff = getattr(row, \"koi_steff\")\n",
    "    logg = getattr(row, \"koi_slogg\") # Stellar Surface Gravity [log10(cm/s**2)]  \n",
    "    feh = getattr(row, \"koi_smet\")\n",
    "    srho = getattr(row, \"koi_srho\") #g/cm3\n",
    "    \n",
    "    #### Store LC Parameters\n",
    "    P = getattr(row, \"koi_period\") # Orbital Period [days]\n",
    "    depth = getattr(row, \"koi_depth\")/1e6\n",
    "    b = getattr(row, \"koi_impact\")\n",
    "    \n",
    "    u1, u2 = quadraticLD(teff,logg,feh)\n",
    "\n",
    "    num_planets = getattr(row, \"koi_count\")\n",
    "    incl =  getattr(row, \"koi_incl\") #in degrees\n",
    "    dor = getattr(row, \"koi_dor\")  #Planet-Star Distance over Star Radius\n",
    "    \n",
    "    time0bk = getattr(row, \"koi_time0bk\")\n",
    "    duration = getattr(row, \"koi_duration\")/24. #in days\n",
    "    \n",
    "    #Planetary parameters\n",
    "    sma = getattr(row, \"koi_sma\")  #Orbit Semi-Major Axis [AU]\n",
    "    sma_solarRad = sma*215\n",
    "    teq = getattr(row, \"koi_teq\") \n",
    "    rp = getattr(row, \"koi_prad\") # in Earth radii\n",
    "    rp_solarRad = getattr(row, \"koi_prad\")*0.009168 # in solar radii\n",
    "    rp_errPos = getattr(row, \"koi_prad_err1\"); rp_errNeg = getattr(row, \"koi_prad_err2\")\n",
    "    rp_err = np.abs((rp_errPos+rp_errNeg)/2.)\n",
    " \n",
    "    if (num_planets == 1):\n",
    "        system = System(kepid, rs, rs_err, smass, smass_err, teff, logg, feh, srho,\n",
    "                    timeLC_BKJD, fluxLC, fluxLC_err, \n",
    "                    P, depth, b, duration, u1, u2, u1-u2, num_planets, incl, None, dor, sma,\n",
    "                    rp, rp_err, teq, None, None, None, None, None, None)\n",
    "\n",
    "        targets.append(system)\n",
    "    else:\n",
    "        print('Star {:s} not stored (koi_count > 1)'.format(str(kepid)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Peak Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_peak_filter(star, mpd, plot):\n",
    "    pos_drops, _ = sig.find_peaks(-star.flux, distance=mpd)\n",
    "    \n",
    "    flux_drops = star.flux[pos_drops]\n",
    "    drops = np.column_stack((pos_drops, flux_drops))\n",
    "    \n",
    "    print(\"Nº of peaks (before mask):\",len(flux_drops))\n",
    "    time_max_flux_drop = (flux_drops).idxmin(axis=None, skipna=True)\n",
    "    depth_guess = 1-min(flux_drops)\n",
    "        \n",
    "    mask_drops = min(flux_drops)+depth_guess*(1/2)\n",
    "    keep_drops = drops[:,1]<=mask_drops\n",
    "        \n",
    "    print(\"\\tRemove peaks > than\", mask_drops)\n",
    "    drops_mask = drops[keep_drops==True]\n",
    "    print(\"Nº of peaks (after mask):\",len(drops_mask[:,1]))\n",
    "    \n",
    "    final_peaks = np.column_stack((drops_mask[:,0],star.time_BKJD[drops_mask[:,0]].values, drops_mask[:,1]))\n",
    "    \n",
    "    #Check if the first peak is too close to the start or end of the cadence \n",
    "    pos_peak_i = int(final_peaks[0,0])\n",
    "    pos_peak_f = int(final_peaks[-1,0])\n",
    "    \n",
    "    dist_transit_i = (final_peaks[1,0]-final_peaks[0,0])/2\n",
    "    dist_transit_f = (final_peaks[-1,0]-final_peaks[-2,0])/2\n",
    "    \n",
    "    if (pos_peak_i-dist_transit_i < 0): \n",
    "        final_peaks = np.delete(final_peaks, 0, axis=0)\n",
    "        \n",
    "    if (pos_peak_f+dist_transit_f>star.time_BKJD.iloc[-1]):  \n",
    "        final_peaks = np.delete(final_peaks, -1, axis=0)\n",
    "    \n",
    "    #Print the updated number of peaks\n",
    "    print(\"Nº of peaks (after checking ends):\", len(final_peaks[:,0]))\n",
    "    \n",
    "    if (plot == True):\n",
    "        plt.figure(figsize=(15,10))\n",
    "        plt.title('KID'+str(star.kepid))\n",
    "        plt.plot(star.time_BKJD, star.flux,'.',star.time_BKJD[drops[:,0]],drops[:,1],'ro')\n",
    "        plt.subplot(2,1,1)\n",
    "        plt.ylabel('Flux'); plt.xlabel('Time BKJD')\n",
    "        plt.plot(star.time_BKJD, star.flux,'.',star.time_BKJD[drops[:,0]],drops[:,1],'ro')\n",
    "        plt.subplot(2,1,2)\n",
    "        plt.ylabel('Flux'); plt.xlabel('Time BKJD')\n",
    "        plt.plot(star.time_BKJD, star.flux,'.',final_peaks[:,1],final_peaks[:,2],'ro')\n",
    "        plt.axhline(y=mask_drops, color='k', linestyle='-')\n",
    "        plt.show(block=False)\n",
    "        time.sleep(1)\n",
    "        plt.close()\n",
    "        \n",
    "    return(final_peaks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for target in targets:\n",
    "        print(\"\\n******\\t\"+str(target.kepid)+\"******\")\n",
    "        \n",
    "        print(len(target.time_BKJD))\n",
    "        total_days = target.time_BKJD.iloc[-1]-target.time_BKJD.iloc[0]\n",
    "        one_day = np.abs(int(len(target.time_BKJD)/total_days))\n",
    "        sensitivity = 2\n",
    "        min_peak_dist = one_day*sensitivity\n",
    "        target.peaks = run_peak_filter(target, min_peak_dist, plot = True)\n",
    "        \n",
    "        num_peaks = len(target.peaks[:,2])\n",
    "         \n",
    "        final_peaks = np.copy(target.peaks)\n",
    "        tpeaks = [None]*num_peaks\n",
    "        fpeaks = [None]*num_peaks\n",
    "        fpeaks_err = [None]*num_peaks\n",
    "        \n",
    "        #Explore peak-by-peak and discard those which are too noisy or unclear\n",
    "        for i in range(num_peaks):\n",
    "            pos_peak, t_peak, f_peak = int(target.peaks[i,0]), int(target.peaks[i,1]), target.peaks[i,2]\n",
    "            if (i!=num_peaks-1): \n",
    "                dist_from_transit = int((target.peaks[i+1,0]-pos_peak)/2) #todo: average separation b/w peaks\n",
    "            else: \n",
    "                dist_from_transit = int((pos_peak-target.peaks[i-1,0])/2)\n",
    "            \n",
    "            if (dist_from_transit/one_day > 1.0): dist_from_transit = int(one_day)\n",
    "            dist_from_transit = int(one_day)\n",
    "            print(\"Transit range [d]:\", dist_from_transit/one_day)\n",
    "            \n",
    "            t_zoom = (target.time_BKJD[pos_peak-dist_from_transit:pos_peak+dist_from_transit]).values\n",
    "            f_zoom = (target.flux[pos_peak-dist_from_transit:pos_peak+dist_from_transit]).values\n",
    "            f_err_zoom = (target.flux_err[pos_peak-dist_from_transit:pos_peak+dist_from_transit]).values\n",
    "\n",
    "            corr_f_zoom = sig.medfilt(f_zoom, 9)\n",
    "            time_max_peak = np.argmin(corr_f_zoom)\n",
    "            tc = t_zoom[time_max_peak]\n",
    "\n",
    "            # Subtract time offset\n",
    "            t_zoom-=tc\n",
    "\n",
    "            #Select [-1,1] interval\n",
    "            mask_int = (t_zoom > -1) & (t_zoom < 1)\n",
    "            t_zoom_mask = t_zoom[mask_int==True]\n",
    "            corr_f_zoom_mask = corr_f_zoom[mask_int==True]\n",
    "            corr_f_zoom_err_mask = f_err_zoom[mask_int==True]\n",
    "\n",
    "            tpeaks[i] = t_zoom_mask \n",
    "            fpeaks[i] = corr_f_zoom_mask \n",
    "            fpeaks_err[i] = corr_f_zoom_err_mask \n",
    " \n",
    "            #print(np.median(corr_f_zoom_mask),np.mean(corr_f_zoom_mask),np.std(corr_f_zoom_mask))\n",
    "\n",
    "            \"\"\"\n",
    "            if (int(np.mean(corr_f_zoom_mask))>1):\n",
    "                print('\\tPeak {:s} is unclear or too noisy -- disregard it.'.format(str(i+1)))\n",
    "                final_peaks[i,:]=0.0\n",
    "                tpeaks[i], fpeaks[i], fpeaks_err[i] = 0, 0, 0\n",
    "            \"\"\"\n",
    "            plt.figure()\n",
    "            plt.title('Transit %s'%str(i+1))\n",
    "            plt.plot(t_zoom_mask,corr_f_zoom_mask,'.')\n",
    "            plt.show(block=False)\n",
    "            time.sleep(1)\n",
    "            plt.close()\n",
    "                \n",
    "        bad_peaks = (final_peaks==0.0).all(1)\n",
    "        target.peaks = final_peaks[bad_peaks == False]\n",
    "        bad_peaks_indx = np.where(bad_peaks)[0]\n",
    "\n",
    "        for index in sorted(bad_peaks_indx, reverse=True):\n",
    "            del tpeaks[index]\n",
    "            del fpeaks[index]\n",
    "            del fpeaks_err[index]\n",
    "\n",
    "        target.tpeaks  = tpeaks\n",
    "        target.fpeaks = fpeaks\n",
    "        target.fpeaks_err = fpeaks_err\n",
    "\n",
    "        print(\"Nº of peaks (updated):\", len(target.peaks[:,0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fitting a Theoretical Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transit Routine (DFM)\n",
    "\n",
    "A Python library for generating light curves of transiting planets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lnlike(theta, timeLC, fluxLC, errorLC, allfixed):\n",
    "    \"\"\"\n",
    "    Calculates the log of the likelihood of the transit model being the right model given the following parameters:\n",
    "    theta[0] = pdepth = (Rp/Rs)^2\n",
    "    theta[1] = pb = the mean impact parameter, measured in stellar radii (not Solar radii). See documentation.\n",
    "    theta[2] = sigma = an additional white noise term\n",
    "    theta[3] = pmass = the mass of the star (controlled via gaussian prior)\n",
    "    theta[4] = pradius = the radius of the star (controlled via gaussian prior)\n",
    "    theta[5] = f0 = the out of eclipse flux\n",
    "    theta[6] = orbital period \n",
    "    theta[7] = time of conjunction\n",
    "    \"\"\"\n",
    "    ecc, mass, masserr, radius, radiuserr, tKep, u1, u2 = allfixed\n",
    "    pdepth, pb, sigma, pmass, pradius, f0, pperiod, ptc = theta \n",
    "    \n",
    "    #Note: pmass and prad (stellar mass and radius) controlled via gaussian prior. By letting M* and R* be free parameters in the model, we allow the stellar density to fluctuate. \n",
    "    \n",
    "    s = transit.System(transit.Central(mu1=u1, mu2=u2, mass = pmass, radius = pradius))\n",
    "    body = transit.Body(radius=np.sqrt(pdepth)*pradius, period=pperiod, t0=ptc, b=np.abs(pb), e=ecc)\n",
    "    \n",
    "    s.add_body(body)\n",
    "    inv_sigma2 = 1.0/(errorLC**2 + sigma**2)\n",
    "    ftheo = s.light_curve(timeLC, texp=tKep, tol=1e-08, maxdepth=4)\n",
    "    ftheo = ftheo-1+f0\n",
    "    return -0.5*(np.sum((fluxLC-ftheo)**2*inv_sigma2 - np.log(inv_sigma2)) + ((pmass-mass)/masserr)**2\n",
    "            + ((pradius-radius)/radiuserr)**2)\n",
    "\n",
    "def lnprior(theta):\n",
    "    ##https://github.com/stan-dev/stan/wiki/Prior-Choice-Recommendations\n",
    "    pdepth, pb, sigma, pmass, pradius, f0, pperiod, ptc = theta\n",
    "    \n",
    "    if ((0 < pb < 1.1) and (0 <= sigma) and (pradius > 0) and (pdepth > 0.0)\n",
    "        and (pmass > 0.0) and (13.5 <= pperiod)) and (ptc**2<0.01):\n",
    "        return 0.0 \n",
    "    \n",
    "    return -np.inf    \n",
    "    \n",
    "def lnprob(theta, timeLC, fluxLC, errorLC, allfixed):\n",
    "    ecc, mass, masserr, radius, radiuserr, tKep, u1, u2 = allfixed\n",
    "    lp = lnprior(theta)\n",
    "    if not np.isfinite(lp):\n",
    "        return -np.inf\n",
    "    return lp + lnlike(theta, timeLC, fluxLC, errorLC, allfixed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_lc(nl, guesses, lc_data, case = 0):\n",
    "    res = op.minimize(nl, guesses, lc_data, options={ 'maxiter': 1e5,'disp': True}, method='Nelder-Mead')\n",
    "    ml_fit = res[\"x\"] #array with: depth_ml, b_ml, sigma_ml, mass_ml, radius_ml, f0_ml, period_ml, tc_ml\n",
    "    return ml_fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = 58.0  #sc = 58 sec\n",
    "tKep = sc/60/60/24  # sc in days\n",
    "period_guess = 250 #randrange(14,500) #uniform(13.5, 500); \n",
    "print(\"Period guess [d]:\", period_guess)\n",
    "t_conj_guess = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_transit_routine(star, t, f, ferr, transit_num):\n",
    "    depth_guess = 1-min(f); #print(\"Depth guess [d]:\", depth_guess)\n",
    "    allfixed = [star.eccen, star.smass, star.smass_err, star.rs, star.rs_err, tKep, star.u1, star.u2]\n",
    "    initial_guesses = [1.2*depth_guess, 0.6, 0.0, star.smass, star.rs, 1.0, period_guess, t_conj_guess]; #print(\"Initial guesses:\", initial_guesses)\n",
    "    \n",
    "    nll = lambda *args: -lnprob(*args)\n",
    "    \n",
    "    params0 = (t, f, 0.0, allfixed)\n",
    "    res0 = fit_lc(nll, initial_guesses, params0)\n",
    "    res0[2]=0.0\n",
    "    print(\"\\t\\t Period (fit 0): {:0.6f} days\".format(res0[6]))\n",
    "\n",
    "    params1 = (t, f, 0.0, allfixed)\n",
    "    res1 = fit_lc(nll, res0, params1)\n",
    "    res1[2]=0.0\n",
    "    print(\"\\t\\t Period (fit 1): {:0.6f} days\".format(res1[6]))\n",
    "\n",
    "    params2 = (t, f, ferr, allfixed)\n",
    "    res2 = fit_lc(nll, res1, params2)\n",
    "    depth_ml, b_ml, sigma_ml, mass_ml, radius_ml, f0_ml, period_ml, tc_ml = res2\n",
    "\n",
    "    print(\"\\t\\t Period (fit 2): {:0.6f} days\".format(res2[6]))\n",
    "    print(\"\\nDepth (fit 2): {0:0.5f} (vs. True = {1:0.5f})\".format(depth_ml, depth/1e6))\n",
    "    print(\"Impact Parameter (fit 2): {0:0.5f} (True = {1:0.5f})\".format(b_ml,b))\n",
    "    \n",
    "    # Compute the theoretical light curve integrated over a Kepler short-cadence exposure time.\n",
    "    s = transit.System(transit.Central(mu1=star.u1, mu2=star.u2, mass=mass_ml, radius=radius_ml))\n",
    "    body = transit.Body(radius=np.sqrt(depth_ml)*radius_ml,period=period_ml,t0=tc_ml,b=b_ml,e=star.eccen)\n",
    "    s.add_body(body)\n",
    "    t_fit = np.arange(-1, 1, tKep*0.01)\n",
    "    f_fit = s.light_curve(t_fit, texp=tKep, tol=1e-08, maxdepth=4)\n",
    "    f_fit = f_fit - 1.0 + f0_ml\n",
    "\n",
    "    fig = plt.figure(figsize=(15,4))\n",
    "    plt.title('Transit %i'%str(transit_num),fontsize=30)\n",
    "    plt.plot(t, f, '.', label = 'Kepler data')\n",
    "    plt.plot(t_fit, f_fit, color='r', lw = 3, label = 'Fit')\n",
    "    plt.xlabel('Time from midtransit [days]')\n",
    "    plt.ylabel('Relative flux')\n",
    "    plt.xlim([min(t),max(t)]) \n",
    "    plt.show()\n",
    "    \n",
    "    star.duration = body.duration #from eq'n 14 in Winn (2010)\n",
    "    print(\"Transit duration: {0:0.2f} hours \".format(star.duration*24))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for target in targets:\n",
    "    print(\"**** Star \"+str(target.kepid)+\" ****\")\n",
    "    num_peaks = len(target.peaks)\n",
    "    if num_peaks == 1:\n",
    "        run_transit_routine(target, target.tpeaks, target.fpeaks, target.fpeaks_err, None)\n",
    "    else: \n",
    "        for i in range(num_peaks):\n",
    "            run_transit_routine(target, target.tpeaks[i], target.fpeaks[i], target.fpeaks_err[i],i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Period [days]: \\n\\t Fit: {0:0.5f} \\n\\tTrue: {1:0.5f}\".format(period_ml,P))\n",
    "print(\"Impact Parameter \\n\\t Fit: {0:0.5f} \\n\\tTrue: {1:0.5f}\".format(b_ml,b))\n",
    "print(\"Depth: \\n\\t Fit: {0:0.5f} \\n\\tTrue: {1:0.5f}\".format(depth_ml,depth))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for system in targets:\n",
    "    #if system.num_planets == 1:\n",
    "    detrend(system, plot_bool = True)\n",
    "        #transit_periodogram(system, durations, per_dict, show_res = True, plot_res = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lnlike(theta, timeLC, fluxLC, errorLC, allfixed):\n",
    "    \"\"\"\n",
    "    theta[0] = pdepth = (Rp/Rs)^2\n",
    "    theta[1] = pb = the impact parameter\n",
    "    theta[2] = pt0 = the time of transit\n",
    "    theta[3] = sigma = an additional white noise term\n",
    "    theta[4] = u1 + u2 = sum of LD coefficients\n",
    "    theta[5] = pmass = the mass of the star (controlled via gaussian prior)\n",
    "    theta[6] = pradius = the radius of the star (controlled via gaussian prior)\n",
    "    theta[7] = f0 = the out of eclipse flux\n",
    "     Gaussian prior: We assume that the parameter we want to fit \n",
    "    is constrained within the range centered on the maximum value of a \n",
    "    Gaussian distribution. \n",
    "    \n",
    "    \"\"\"   \n",
    "    pdepth, pb, pt0, sigma, sumLD, pmass, pradius, f0 = theta\n",
    "    period, ecc, mass, masserr, radius, radiuserr, diffLD, tKep = allfixed\n",
    "    \n",
    "    u1 = 0.5*(sumLD+diffLD) \n",
    "    u2 = sumLD-u1\n",
    "    \n",
    "    s = transit.System(transit.Central(mu1 = u1, mu2 = u2, mass = pmass, radius = pradius))\n",
    "    body = transit.Body(r = np.sqrt(pdepth)*pradius, period = period, t0 = pt0, b = np.abs(pb), e = ecc)\n",
    "    s.add_body(body)\n",
    "    \n",
    "    sigma2 = errorLC**2 + sigma**2\n",
    "    ftheo = s.light_curve(timeLC, texp = tKep, tol = 10e-2, maxdepth = 4)\n",
    "    ftheo = ftheo - 1.0 + f0\n",
    "    \n",
    "    return -0.5*(np.sum(((fluxLC-ftheo)**2)/sigma2 - np.log(1.0/sigma2)) +\n",
    "                 ((pmass-mass)/masserr)**2 + \n",
    "                 ((pradius-radius)/radiuserr)**2) # Chi Squared\n",
    "\n",
    "def lnprior(theta): \n",
    "    # This function ensures that our best estimates make physical sense.\n",
    "    pdepth, pb, pt0, sigma, sumLD, pmass, pradius, f0 = theta\n",
    "    if (0.2 < sumLD < 1.0) and (0 <= pb <0.9) and (0 <= sigma) and (pradius > 0) and (pdepth > 0) and (pmass > 0):\n",
    "        return 0.0 \n",
    "    return -np.inf\n",
    "\n",
    "def lnprob(theta, timeLC, fluxLC, errorLC, allfixed):\n",
    "    lp = lnprior(theta)\n",
    "    if not np.isfinite(lp):\n",
    "        return -np.inf\n",
    "    return lp + lnlike(theta, timeLC, fluxLC, errorLC, allfixed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_fit(system):\n",
    "    \n",
    "    perTP_no_Units = np.float(np.copy(system.perTP))\n",
    "    duration_no_units = np.float(np.copy(system.durationTP))\n",
    "\n",
    "    allfixed = [perTP_no_Units, system.eccen, system.smass, system.smass_err, \n",
    "                system.rs, system.rs_err, system.diffld, tKep]\n",
    "    \n",
    "    nll = lambda *args: -lnprob(*args)\n",
    " \n",
    "    # Minimization of the function \"nll\"\n",
    "    result = op.minimize(nll, [1.2*system.depthTP, 0.0, 0.0, 0.0, system.u1+system.u2, system.smass, system.rs, 0.0], \n",
    "                             args = (np.array(system.folded_time), np.array(system.folded_flux), \n",
    "                                     system.rms_ootTP, allfixed),\n",
    "                             options = {'disp': True}, method  ='Nelder-Mead')\n",
    "    \n",
    "    # Store best estimates in \"result[\"x\"]\n",
    "    depth_ml, b_ml,  t0_ml, sigma_ml, sumLD_ml, mass_ml, radius_ml, f0_ml  = result[\"x\"]\n",
    "\n",
    "    system.optimize_loop1 = result[\"x\"]\n",
    "\n",
    "    # Readjust LD coefficients. \n",
    "    u1_ml = 0.5*(sumLD_ml + system.diffld)\n",
    "    u2_ml = sumLD_ml - u1_ml\n",
    "\n",
    "    # Compute each transit LC integrated over a Kepler long cadence exposure time \n",
    "    # with the result derived from optimization and plot theoretical model and observed data.\n",
    "\n",
    "    s = transit.System(transit.Central(mu1 = u1_ml, mu2 = u2_ml, mass = mass_ml, radius = radius_ml))\n",
    "\n",
    "    body = transit.Body(r = np.sqrt(depth_ml)*radius_ml, period = perTP_no_Units, t0 = t0_ml, \n",
    "                            b = b_ml, e = system.eccen)\n",
    "\n",
    "    s.add_body(body)\n",
    "    t_theory = np.arange(-1.0, 1.0, tKep)\n",
    "    f_theory = s.light_curve(t_theory, texp = tKep, tol = 1e-2, maxdepth = 5)\n",
    "    f_theory = f_theory - 1.0 + f0_ml\n",
    "    \n",
    "    fig = plt.figure()\n",
    "    plt.plot(24.*system.folded_time, system.folded_flux,'.') \n",
    "    plt.plot(24.*t_theory, f_theory,'.')\n",
    "    plt.title('KID' + str(system.kepid))\n",
    "    plt.xlabel('Time from midtransit [hours]')\n",
    "    plt.ylabel('De-trended Flux')\n",
    "    plt.xlim([-duration_no_units*24., duration_no_units*24.])\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sc = 58.0  #sc = 58 sec -> \n",
    "tKep = sc*(1./60.)*(1./60.)*(1./24.)  # sc in days\n",
    "\n",
    "for system in targets:\n",
    "    if system.num_planets == 1:\n",
    "        print \"KID\"+str(system.kepid)+':'\n",
    "        find_best_fit(system)\n",
    "        \n",
    "        print \"Depth:\", system.optimize_loop1[0]\n",
    "        print \"Impact parameter:\", system.optimize_loop1[1],\"vs Kepler reported value:\", system.impact\n",
    "        print \"Initial transit time (Phase-folded LC):\", system.optimize_loop1[2]\n",
    "        print \"Mass of the star (Solar units):\", system.optimize_loop1[5],\"vs Kepler reported value:\", system.smass\n",
    "        print \"Radius of the star (Solar units):\",  system.optimize_loop1[6], \"vs Kepler reported value:\", system.rs\n",
    "        print \"Out-of-transit flux\",  system.optimize_loop1[7],\"\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identify Transits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_transits(system):\n",
    "    \n",
    "    t_initial = min(system.time_BKJD)\n",
    "    t_end = max(system.time_BKJD)\n",
    "    t0 = system.t\n",
    "    \n",
    "    n_min = int((t_initial-t0)/system.per)\n",
    "    n_max = int((t_end-t0)/system.per+1.)\n",
    "    n = np.arange(n_min, n_max)\n",
    "\n",
    "    transit_times = t0+n*system.per\n",
    "    transit_times = transit_times[transit_times>t_initial] \n",
    "    transit_times = transit_times[transit_times<t_end]\n",
    "    system.transits = transit_times\n",
    "    \n",
    "    #print \"Transits should occur at:\", system.transits,\"\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fold(system):\n",
    "    #Returns time values ranging between -\"transit_range\" to +\"transit_range\". Data points \n",
    "    #which occur exactly at ``phase`` or an integer multiple of `phase + n*period` have time value 0.0. \n",
    "    #Note: transit window = 2*transit_range\n",
    "    \n",
    "    phase = system.time0bk\n",
    "    transit_range = (system.duration)/2.\n",
    "    print \"Transit range:\", transit_range\n",
    "    \n",
    "    fold_time = ((system.time_BKJD-phase+transit_range*system.per)/system.per)%1-transit_range\n",
    "    sorted_args = np.argsort(fold_time)   \n",
    "    system.foldedTime = fold_time[sorted_args]\n",
    "    system.flux = system.flux[sorted_args]\n",
    "    system.flux_err = system.flux_err[sorted_args] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transit_window(system):\n",
    "    window = system.duration # In days\n",
    "    \n",
    "    total_points = 0\n",
    "    \n",
    "    for i in range(0,len(system.transits)):\n",
    "        residual = system.time_BKJD - system.transits[i]\n",
    "        points_in_transit = np.abs(residual) <= window\n",
    "        total_points += np.sum(points_in_transit)\n",
    "\n",
    "    time_in_transit = np.empty(total_points)\n",
    "    flux_in_transit = np.empty(total_points)\n",
    "    flux_err_in_transit = np.empty(total_points)\n",
    "    flag_transit = np.empty(total_points)\n",
    "    mid_trans = np.empty(total_points)\n",
    "\n",
    "    total_points = 0\n",
    "\n",
    "    for i in range(0, len(system.transits)):\n",
    "        points_in_transit = np.abs(system.time_BKJD - system.transits[i]) <= window\n",
    "        count_points = np.sum(points_in_transit)\n",
    "        time_in_transit[(0 + total_points):(count_points + total_points)] = system.time_BKJD[points_in_transit]\n",
    "        flux_in_transit[(0 + total_points):(count_points + total_points)] = system.flux[points_in_transit]\n",
    "        flux_err_in_transit[(0 + total_points):(count_points + total_points)] = system.flux_err[points_in_transit]\n",
    "        \n",
    "        flag_transit[(0 + total_points):(count_points + total_points)] = i\n",
    "        mid_trans[(0 + total_points):(count_points + total_points)] = system.transits[i] \n",
    "        total_points += count_points\n",
    "   \n",
    "    system.flag = flag_transit\n",
    "    system.f_trans = flux_in_transit\n",
    "    system.f_trans_err = flux_err_in_transit\n",
    "    system.t_trans = time_in_transit\n",
    "    system.dt = time_in_transit - mid_trans #time array for each transit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def colTrans(system):\n",
    "    color_code = plt.figure(figsize=(17,5))\n",
    "    ax1 = plt.subplot(121)\n",
    "    ax2 = plt.subplot(122)\n",
    "    \n",
    "    for i in range(0,len(system.transits)):\n",
    "        transitBool = (system.flag == i)\n",
    "        \n",
    "        if i % 2 == 0: #even transit\n",
    "            ax1.plot(system.t_trans[transitBool], system.f_trans[transitBool], '.', color = 'red', label = 'Even')\n",
    "            ax2.plot(system.dt[transitBool], system.f_trans[transitBool],'.', color = 'red', label = 'Even')\n",
    "        else:\n",
    "            ax1.plot(system.t_trans[transitBool], system.f_trans[transitBool], '.', color = 'green', label = 'Odd')\n",
    "            ax2.plot(system.dt[transitBool], system.f_trans[transitBool],'.', color = 'green', label = 'Odd')\n",
    "    \n",
    "    ax1.legend(); ax2.legend(); \n",
    "    ax1.set_title('KID'+ str(system.kepid), fontsize = 14); \n",
    "    ax2.set_title('Folded LC for KID'+ str(system.kepid), fontsize = 14)\n",
    "    ax1.set_ylabel('Normalized Flux');\n",
    "    ax1.set_xlabel('BJD-2454833 (days) '); ax2.set_xlabel('Time from midtransit (days)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "def export_folded_lc(system, fraction):\n",
    "    len_file = len(system.f_trans)\n",
    "    cut = random.sample(zip(system.f_trans, system.f_trans_err, system.dt), int(fraction*len_file/100))\n",
    "    cut_flux, cut_flux_err, cut_time = zip(*cut)\n",
    "    \n",
    "    system.dt = np.array(cut_time) #use np.array to convert from tuple to array\n",
    "    system.f_trans = np.array(cut_flux)\n",
    "    system.f_trans_err = np.array(cut_flux_err)\n",
    "    \n",
    "    cut_fold_lc = pd.DataFrame(OrderedDict({'Phase': cut_time, 'Flux': cut_flux, 'Flux_Err': cut_flux_err}))\n",
    "     \n",
    "    np.savetxt('/Users/mbadenas/Documents/Master UAB/Tesis UAB/folded_LC/cut'+str(fraction) \\\n",
    "               +'_fold_KID'+str(system.kepid)+'.txt', \n",
    "               cut_fold_lc.values, fmt='%f', delimiter=\"\\t\", header=\"Phase\\t\\tFlux (normalized)\\t\\tFlux error\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cut_fraction = 50 #in %. If 100, the entire light curve is used.\n",
    "one_planet = 0\n",
    "\n",
    "for system in targets:\n",
    "    if system.num_planets==1:\n",
    "        find_transits(system)\n",
    "        fold(system)\n",
    "        transit_window(system)\n",
    "        \n",
    "        fig = plt.figure(figsize=(17,5))\n",
    "        ax1 = plt.subplot(121)\n",
    "        ax2 = plt.subplot(122)\n",
    "    \n",
    "        ax1.plot(system.time_BKJD, system.flux,'.')\n",
    "        ax1.plot(system.transits, np.ones(len(system.transits))*min(system.flux),'ro')  \n",
    "        ax1.set_xlabel('BJD-2454833 (days)'); \n",
    "        ax1.set_ylabel('Normalized Flux'); \n",
    "        ax1.set_title('KID'+str(system.kepid)); \n",
    "        \n",
    "        ax2.plot(system.foldedTime, system.flux,'.')\n",
    "        ax2.set_xlabel('Time from midtransit (days)'); \n",
    "        ax2.set_ylabel('Normalized Flux')\n",
    "        ax2.set_title('Folded LC for '+str(system.kepid)) \n",
    "        \n",
    "        colTrans(system)\n",
    "        export_folded_lc(system, cut_fraction)\n",
    "        \n",
    "        one_planet += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Theoretical model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Todo: standard dev of out-of-transit flux for each identified transit "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
